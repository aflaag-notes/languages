\documentclass[a4paper, 12pt]{report}

\usepackage[dvipsnames]{xcolor}

%%%%%%%%%%%%%%%%
% Set Variables %
%%%%%%%%%%%%%%%%

\def\useItalian{1}  % 1 = Italian, 0 = English

\def\courseName{Linguaggi di Programmazione}

\def\coursePrerequisites{
    \begin{itemize}
        \item Metodi Matematici per l'Informatica
    \end{itemize}
}

\def\book{}

% \def\authorName{Simone Bianco}
% \def\email{bianco.simone@outlook.it}
% \def\github{https://github.com/Exyss/university-notes}
% \def\linkedin{https://www.linkedin.com/in/simone-bianco}

\def\authorName{Alessio Bandiera}
\def\email{alessio.bandiera02@gmail.com}
\def\github{https://github.com/aflaag-notes}
\def\linkedin{https://www.linkedin.com/in/alessio-bandiera-a53767223}

%%%%%%%%%%%%
% Packages %
%%%%%%%%%%%%

\usepackage{../../packages/Nyx/nyx-packages}
\usepackage{../../packages/Nyx/nyx-styles}
\usepackage{../../packages/Nyx/nyx-frames}
\usepackage{../../packages/Nyx/nyx-macros}
\usepackage{../../packages/Nyx/nyx-title}
\usepackage{../../packages/Nyx/nyx-intro}

%%%%%%%%%%%%%%
% Title-page %
%%%%%%%%%%%%%%

\logo{../../packages/Nyx/logo.png}

\if\useItalian1
    \institute{\curlyquotes{\hspace{0.25mm}Sapienza} Università di Roma}
    \faculty{Ingegneria dell'Informazione,\\Informatica e Statistica}
    \department{Dipartimento di Informatica}
    % \subtitle{Appunti integrati con il libro \book}
    \author{\textit{Autore}\\\authorName}
\else
    \institute{\curlyquotes{\hspace{0.25mm}Sapienza} University of Rome}
    \faculty{Faculty of Information Engineering,\\Informatics and Statistics}
    \department{Department of Computer Science}
    \subtitle{Lecture notes integrated with the book \book}
    \author{\textit{Author}\\\authorName}
\fi

\title{\courseName}
\date{\today}

% \supervisor{Linus \textsc{Torvalds}}
% \context{Well, I was bored\ldots}

%%%%%%%%%%%%
% Document %
%%%%%%%%%%%%

\begin{document}
    \maketitle

    % The following style changes are valid only inside this scope 
    {
        \hypersetup{allcolors=black}
        \fancypagestyle{plain}{%
        \fancyhead{}        % clear all header fields
        \fancyfoot{}        % clear all header fields
        \fancyfoot[C]{\thepage}
        \renewcommand{\headrulewidth}{0pt}
        \renewcommand{\footrulewidth}{0pt}}

        \romantableofcontents
    }

    \introduction

    %%%%%%%%%%%%%%%%%%%%%

    \chapter{Induzione}
    
    \section{Algebre induttive}

    \subsection{Assiomi di Peano}

    \begin{frameddefn}[label={peano}]{Assiomi di Peano}
        Gli \tbf{assiomi di Peano} sono 5 assiomi che definiscono l'insieme $\N$, e sono i seguenti:

        \begin{enumerate}[label=\roman*), font=\itshape]
            \item $0 \in \N$
            \item $\exists \func{\mathrm{succ}}{\N}{\N}$, o equivalentemente, $\forall x \in \N \quad \mathrm{succ}(x) \in \N$
            \item $\forall x, y \in \N \quad x \neq y \implies \mathrm{succ}(x) \neq \mathrm{succ}(y)$
            \item $\nexists x \in \N \mid \mathrm{succ}(x) = 0$
            \item $\forall S \subseteq \N \quad (0 \in S \land (\forall x \in S \quad \mathrm{succ}(x) \in S)) \implies S = \N$
        \end{enumerate}
    \end{frameddefn}

    \begin{example}[$\N$ di von Neumann]
        Una rappresentazione dell'insieme dei numeri naturali $\N$ alternativa alla canonica $$\N := \{0, 1, 2, \ldots \}$$ è stata fornita da John von Neumann. Indicando tale rappresentazione con $\aleph$, si ha che, per Neumann $$\begin{array}{c} 0_\aleph := \varnothing  = \{\} \\ 1_\aleph := \{ 0_\aleph \} = \{ \{ \}\} \\ 2_\aleph := \{0_\aleph, 1_\aleph\} = \{\{\}, \{\{ \}\}\} \\ \vdots \end{array}$$ e la funzione $\mathrm{succ}_\aleph$ è definita come segue $$\funcmap{\mathrm{succ}_\aleph}{\aleph}{\aleph}{x_\aleph}{x_\aleph \cup \{x_\aleph\} = \{\mu_\aleph \in \aleph \mid |\mu_\aleph| \le |x_\aleph|\}}$$ ed in particolare $\forall x_\aleph \in \aleph \quad |x_\aleph| + 1 = |\mathrm{succ}_\aleph(x_\aleph)|$.

        È possibile verificare che tale rappresentazione di $\N$ soddisfa gli assiomi di Peano, in quanto:

        \begin{enumerate}[label=\roman*), font=\itshape]
            \item $0_\aleph := \varnothing \in \aleph$;
            \item $\exists \func{\mathrm{succ}_\aleph}{\aleph}{\aleph}$, definita precedentemente;
            \item $\forall x_\aleph, y_\aleph \in \aleph \quad x_\aleph \neq y_\aleph \implies |x_\aleph| \neq |y_\aleph| \implies  |\mathrm{succ}_\aleph(x_\aleph)| \neq |\mathrm{succ}_\aleph(y_\aleph)| \implies \mathrm{succ}_\aleph(x_\aleph) \neq \mathrm{succ}_\aleph(y_\aleph)$;
            \item per assurdo, sia $x_\aleph \in \aleph$ tale che $\mathrm{succ}_\aleph(x_\aleph) = 0_\aleph := \varnothing$; per definizione $\mathrm{succ}_\aleph(x_\aleph) := \{\mu_\aleph \in \aleph \mid |\mu_\aleph| \le |x_\aleph|\}$, ma non esiste $\mu_\aleph \in \aleph$ con cardinalità minore o uguale 0, e dunque $\nexists x_\aleph \in \aleph \mid \mathrm{succ}_\aleph(x_\aleph) = 0_\aleph$;
            \item per assurdo, sia $S \subseteq \aleph$ tale che $0_\aleph \in S$ e $\forall x_S \in S \quad \mathrm{succ}_\aleph(x_S) \in S$ ma $S \neq \aleph \iff \aleph - S \neq \varnothing \implies \exists \zeta_\aleph \in \aleph - S$, ed in particolare $\zeta_\aleph \neq 0_\aleph$; $\aleph$ è chiuso su $\mathrm{succ}_\aleph$ per il secondo assioma di Peano, e dunque $\zeta_\aleph \neq 0_\aleph \implies \exists \zeta'_\aleph \in \aleph \mid \mathrm{succ}_\aleph(\zeta'_\aleph) = \zeta_\aleph$, e sicuramente $\zeta'_\aleph \notin S$, poiché altrimenti $\zeta_\aleph \in S$ anch'esso in quanto $S$ è chiuso rispetto a $\mathrm{succ}_\aleph$; allora, ripetendo il ragionamento analogo per l'intera catena di predecessori, $S$ risulterebbe essere vuoto, ma ciò è impossibile poiché $0_\aleph \in S$ in ipotesi $\lightning$.
        \end{enumerate}
    \end{example}

    \begin{framedprinc}[label={induction}]{Principio di Induzione}
        Sia $P$ una proprietà che vale per $n = 0$, e dunque $P(0)$ è vera; inoltre,  per ogni $n \in \N$ si ha che $P(n) \implies P(n + 1)$; allora, $P(n)$ è vera per ogni $n \in \N$.

        In simboli, utilizzando la notazione della logica formale, si ha che $$\dfrac{P(0) \quad P(n) \implies P(n + 1)}{\forall n \quad P(n)}$$
    \end{framedprinc}

    \begin{framedobs}{Quinto assioma di Peano}
        Si noti che il quinto degli assiomi di Peano (della \cref{peano}) equivale al principio di induzione (descritto nel \cref{induction}). Infatti, il quinto assioma afferma che qualsiasi sottoinsieme $S$ di $\N$ avente lo 0, e caratterizzato dalla chiusura sulla funzione di successore $\mathrm{succ}$, coincide con $\N$ stesso.
    \end{framedobs}

    \subsection{Algebre induttive}

    \begin{frameddefn}{Segnatura di una funzione}
        Data una funzione $f$, si definisce $$\func{f}{A}{B}$$ come \tbf{segnatura della funzione} $f$, dove $A$ è detto \tbf{dominio}, denotato con $\dom{(f)}$ e $B$ è detto \tbf{codominio} di $f$.
    \end{frameddefn}

    \begin{frameddefn}{Algebra}
        Una \tbf{struttura algebrica}, o più semplicemente \tbf{algebra}, consiste di un insieme \tit{non vuoto} --- talvolta chiamato \tbf{insieme sostegno} (\tit{carrier set} o \tit{domain}) --- fornito di una o più operazioni su tale insieme, quest'ultime caratterizzate da un numero finito di assiomi da soddisfare.

        Se $A$ è un insieme sostegno, e $\gamma_1, \ldots , \gamma_n$ sono delle operazioni definite su $A$, allora con $$(A, \gamma_1, \ldots, \gamma_n)$$ si indica l'algebra costituita da tali componenti, e questo simbolismo prende il nome di \tbf{segnatura dell'algebra}.
    \end{frameddefn}

    \begin{example}[Algebre]
        Esempi di strutture algebriche con un'operazione binaria sono i seguenti:

        \begin{itemize}
            \item semigruppi
            \item monoidi
            \item gruppi
            \item gruppi abeliani
        \end{itemize}
    \end{example}

    \begin{example}[Algebre]
        Esempi di strutture algebriche con due operazioni binarie sono i seguenti:

        \begin{itemize}
            \item semianelli
            \item anelli
            \item campi
        \end{itemize}
    \end{example}

    \begin{frameddefn}{Insieme unità}
        Con \tbf{insieme unità} si intende un qualsiasi insieme avente cardinalità pari ad 1. L'insieme unità verrà indicato attraverso il simbolo $\1$, e dunque $\abs{\1} = 1$.
    \end{frameddefn}

    \begin{frameddefn}{Funzione nullaria}
        Dato un insieme A, con \tbf{funzione nullaria} si intende una qualsiasi funzione con segnatura $$\func{f}{\1}{A}$$
    \end{frameddefn}

    \begin{framedobs}[label={inj null}]{Iniettività della funzione nullaria}
        Si noti che ogni funzione nullaria è iniettiva, poiché il dominio è costituito da un solo elemento.
    \end{framedobs}

    \begin{frameddefn}[label={inductive algebra}]{Algebra induttiva}
        Sia $A$ un insieme, e siano $\gamma_1, \ldots, \gamma_n$ funzioni definite su $A$ di arbitraria arietà; allora, $(A, \gamma_1, \ldots, \gamma_n)$ è definita \tbf{algebra induttiva} se si verificano le seguenti:

        \begin{enumerate}[label=\roman*), font=\itshape]
            \item $\gamma_1, \ldots, \gamma_n$ sono iniettive
            \item $\forall i, j \in [1, n] \mid i \neq j \quad \im(\gamma_i) \cap \im(\gamma_j) = \varnothing$, ovvero, le immagini dei costruttori sono a due a due disgiunte
            \item $\forall S \subseteq A \quad (\forall i \in [1, n], a_1, \ldots, a_k \in S, k \in \N  \quad \gamma_i(a_1, \ldots, a_k) \in S) \implies S = A$, o equivalentemente, in $A$ non devono essere contenute algebre induttive.
        \end{enumerate}

        Le funzioni $\gamma_1, \ldots, \gamma_n$ prendono il nome di \tbf{costruttori dell'algebra}.
    \end{frameddefn}

    \begin{framedobs}[label={third inductive algebra}]{Terzo assioma delle algebre induttive}
        Si noti che nel terzo assioma della \cref{inductive algebra} anche $S = \varnothing$ è un valido sottoinsieme di $A$, ma poiché non esistono $a_1, \ldots, a_k \in \varnothing$, in esso ogni qualificazione è vera a vuoto; allora ogni algebra che ammette l'insieme vuoto risulta essere non induttiva necessariamente (a meno dell'algebra vuota).
        
        Di conseguenza, questo terzo assioma forza la necessità della presenza di un costruttore nullario all'interno di ogni algebra induttiva, in modo da non poter ammettere $S = \varnothing$, poiché l'algebra deve essere chiusa su ognuno dei suoi costruttori, e dunque grazie al costruttore nullario è sempre presente almeno un elemento all'interno di essa.
    \end{framedobs}

    \begin{nonexample}[Numeri naturali]
        $(\N, +)$ non è un algebra induttiva, poiché esistono $x_1, x_2, x_3, x_4 \in \N$ con $x_1 \neq x_3$ e $x_2 \neq x_4$ tali che $x_1 + x_2 = x_3 + x_4$; ad esempio, 2 + 3 = 5 = 1 + 4, e 2 $\neq$ 1, 3 $\neq$ 4.
    \end{nonexample}

    \begin{nonexample}[Algebra di Boole]
        Dato l'insieme $B = \{ \mathrm{true}, \mathrm{false}\}$, e la funzione $\lnot$ definita come segue: $$\funcmap{\lnot}{B}{B}{x}{\left \{ \begin{array}{ll} \mathrm{false} & x = \mathrm{true} \\ \mathrm{true} & x = \mathrm{false} \end{array} \right.}$$ è possibile dimostrare che l'algebra $(B, \lnot)$ non è induttiva; infatti, nonostante $\lnot$ sia iniettiva, e la seconda proprietà della \cref{inductive algebra} sia vera a vuoto, $(B, \lnot)$ non presenta costruttore nullario, e dunque non può costituire un'algebra induttiva (si noti l'\cref{third inductive algebra}).

        Inoltre, si noti che anche l'algebra $(B, \lnot, \mathrm{true}_f)$, dove $\mathrm{true}_f$ è la funzione nullaria definita come segue: $$\funcmap{\mathrm{true}_f}{\1}{B}{x}{\mathrm{true}}$$ non è induttiva, poiché $$\mathrm{true} \in \im(\lnot) \implies \im(\mathrm{true}_f) \cap \im(\lnot) \neq \varnothing$$
    \end{nonexample}

    \begin{framedprop}[label={N inductive}]{Algebra induttiva di $\N$}
        Sia $\mathrm{zero}$ la funzione definita come segue $$\funcmap{\mathrm{zero}}{\1}{\N}{x}{0}$$ allora l'algebra $(\N, \mathrm{zero}, \succfn)$ è induttiva.
    \end{framedprop}

    \begin{proof}
        Si noti che:

        \begin{enumerate}[label=\roman*), font=\itshape]
            \item $\mathrm{zero}$ e $\succfn$ sono iniettive, poiché
                \begin{itemize}
                    \item $\mathrm{zero}$ è iniettiva per l'\cref{inj null}
                    \item $\mathrm{succ}$ è iniettiva per il terzo assioma di Peano (si veda la \cref{peano})
                \end{itemize}
            \item $\im(\mathrm{succ}) \cap \im(\mathrm{zero}) = \left(\N - \{0\}\right) \cap \{0\} = \varnothing$
            \item sia $S \subseteq \N$ tale che $\forall x \in S \quad \soe{l}{\mathrm{zero}(x) \in S \\ \succfn(x) \in S}$; si noti che, poiché $\forall x \in S \quad \mathrm{zero}(x) \in S$, allora $0 \in S$, e poiché $S$ è anche chiuso rispetto a $\succfn$, per la \cref{peano} si ha che $S = \N$ necessariamente.
        \end{enumerate}

        Allora, segue la tesi.
    \end{proof}

    \begin{frameddefn}{Omomorfismo}
        Un \tbf{omomorfismo} è una funzione tra due algebre aventi stessa segnatura, tale da preservare le loro strutture.

        Formalmente, siano $(A, \mu_1, \ldots, \mu_n)$ e $(B, \delta_1, \ldots, \delta_n)$ due algebre tali che ogni funzione $\mu_i$ abbia la stessa arietà e lo stesso numero di parametri esterni (denotati con $k$) di $\delta_i$; allora, una funzione $\func{f}{A}{B}$ è detta \tbf{omomorfismo} tra le due algebre, se e solo se $$\centeredsoe{f(\mu_1(a_\alpha, \ldots, a_\beta, k_\alpha, \ldots, k_\gamma)) = \delta_1(f(a_\alpha), \ldots, f(a_\beta), k_\alpha, \ldots, k_\gamma) \\ \vdots \\ f(\mu_n(a_\eta, \ldots, a_\omega, k_\eta, \ldots k_\nu)) = \delta_n(f(a_\eta), \ldots, f(a_\omega), k_\eta, \ldots, k_\nu)}$$

        Se l'omomorfismo è da un'algebra in sé stessa, prende il nome di \tbf{endomorfismo}.
    \end{frameddefn}

    \begin{example}[Omomorfismi]
        \label{homo}
        Si considerino i gruppi $(\R, +)$ e $(\R_{> 0}, \cdot)$, e sia $f$ definita come segue: $$\funcmap{f}{\R}{\R_{> 0}}{x}{e^x}$$ allora, si ha che $$\forall x, y \in \R \quad f(x) \cdot f(y) = e^x \cdot e^y = e^{x + y} = f(x + y)$$ dunque $f$ è un omomorfismo di gruppi.
    \end{example}

    \begin{framedprop}[label={comp homo}]{Composizione di omomorfismi}
        Siano $(A, \gamma_1, \ldots, \gamma_n)$, $(B, \delta_1, \ldots, \delta_n)$ e $(C, \mu_1, \ldots, \mu_n)$ tre algebre aventi la stessa segnatura, e siano $\func{f}{A}{B}$ e $\func{g}{B}{C}$ due omomorfismi; allora $g \circ f$ è un omomorfismo.
    \end{framedprop}

    \begin{proof}
        Per dimostrare la tesi, è necessario dimostrare che $$\forall i \in [1, k] \quad (g \circ f)(\gamma_i(a_{\alpha_i}, \ldots, a_{\beta_i})) = \mu_i((g \circ f)(a_{\alpha_i}), \ldots (g \circ f)(a_{\beta_i}))$$ allora, si ha che \centeredeq{0.9}{$\forall i \in [1, k] \quad g(f(\gamma_i(a_{\alpha_i}, \ldots, a_{\beta_i}))) = g(\delta_i(f(a_{\alpha_i}), \ldots, f(a_{\beta_i}))) = \mu_i(g(f(a_{\alpha_i})), \ldots, g(f(a_{\beta_i})))$} e dunque segue la tesi.
    \end{proof}

    \begin{frameddefn}{Isomorfismo}
        Un \tbf{isomorfismo} è un omomorfismo biettivo.

        Se tra due strutture algebriche $A$ e $B$ esiste un isomorfismo, queste sono dette \tbf{isomorfe}, e tale proprietà è indicata dal simbolismo $$A \cong B$$ Se l'isomorfismo è da un'algebra in sé stessa, prende il nome di \tbf{automorfismo}.
    \end{frameddefn}

    \begin{example}[Isomorfismi]
        Si consideri l'omomorfismo dell'\cref{homo}; si noti che $$\forall x, y \in \R \mid x \neq \R \quad e^x \neq e^y \implies f(x) \neq f(y)$$ e dunque $f$ è iniettiva; inoltre $$\forall y \in \R_{> 0} \quad \exists x \in \R \mid f(x) = e^x = y \iff y = \ln(x)$$ e dunque $f$ è suriettiva. Allora, $f$ è biettiva, e poiché è un omomorfismo, risulta essere un isomorfismo.
    \end{example}

    \begin{framedobs}[label={iden auto}]{L'automorfismo dell'identità}
        Sia $(A, \gamma_1, \ldots, \gamma_n)$ un'algebra, e si consideri la funzione identità su $A$ $$\funcmap{\id}{A}{A}{x}{x}$$ Si noti che $$\forall i \in [1, n] \quad \id(\gamma_i(a_{\alpha_i}, \ldots, a_{\beta_i})) = \gamma_i(a_{\alpha_i}, \ldots, a_{\beta_i}) = \gamma_i(\id(a_{\alpha_i}), \ldots, \id(a_{\beta_i}))$$ dunque $\id$ è un endomorfismo su $A$, e poiché la funzione identità è sia iniettiva che suriettiva, $\id$ è sempre un automorfismo per qualsiasi algebra $A$.
    \end{framedobs}

    \subsection{Lemma di Lambek}

    \begin{framedprop}[label={bij}]{Biettività ed invertibilità}
        Sia $f$ una funzione, allora $f$ è biettiva se e solo se esiste la sua inversa.
    \end{framedprop}

    \begin{proof}
        Omessa.
    \end{proof}

    \begin{framedprop}[label={alg same sign}]{Algebre con stessa segnatura}
        Data un'algebra induttiva $(A, \gamma_1, \ldots, \gamma_n)$, per ogni algebra --- \tit{non necessariamente induttiva} --- $(B, \delta_1, \ldots, \delta_n)$, avente la stessa segnatura di $A$, esiste unico un omomorfismo $\func{f}{A}{B}$.
    \end{framedprop}

    \begin{proof}
        Omessa.
    \end{proof}

    \begin{framedcor}[label={iden inductive alg}]{Identità nelle algebre induttive}
        Sia $A$ un'algebra induttiva, e sia $\func{f}{A}{A}$ un suo endomorfismo; allora $f = \id$.
    \end{framedcor}

    \begin{proof}
        Si noti che, per l'\cref{iden auto}, esiste l'automorfismo $\id$ su $A$, ma per la \cref{alg same sign}, poiché $A$ è un'algebra induttiva, esiste un unico omomorfismo $\func{f}{A}{A}$, che deve allora necessariamente coincidere con $\id$.
    \end{proof}

    \begin{framedlem}{Lemma di Lambek (versione ridotta)}
        Siano $(A, \gamma_1, \ldots, \gamma_n)$ e $(B, \delta_1, \ldots, \delta_n)$ due algebre induttive aventi stessa segnatura; allora $A \cong B$.
    \end{framedlem}

    \begin{proof}
        Per la \cref{alg same sign}, poiché $A$ è un'algebra induttiva, e $B$ ha la stessa segnatura di $A$, esiste unico un omomorfismo $\func{f}{A}{B}$; viceversa, poiché $B$ è un'algebra induttiva, ed $A$ ha la stessa segnatura di $B$, esiste unico un omomorfismo $\func{g}{B}{A}$. Si noti che, per la \cref{comp homo}, la funzione $\funcmap{g \circ f}{A}{A}{x}{g(f(x))}$ risulta essere un omomorfismo; allora, poiché $A$ è un'algebra induttiva, per il \cref{iden inductive alg}, si ha che $$g \circ f = \id \iff f^{-1} = g \iff f \ \mathrm{biettiva}$$ (si veda la \cref{bij}) e poiché $f$ è un omomorfismo, segue che $A \cong B$.
    \end{proof}

    \section{Strutture dati induttive}

    \subsection{Liste}

    \begin{frameddefn}{Liste}
        Una \tbf{lista} è una collezione ordinata di elementi, e l'insieme delle liste di lunghezza finita viene denotato con $\ttt{List<T>}$, dove $\ttt T$ è il tipo degli elementi che le liste contengono; inoltre, il simobolo $\ttt T$ identificherà l'insieme di tutti gli oggetti aventi tipo $\ttt T$.

        Dati $a_1, \ldots, a_n \in \ttt T$, una lista $l \in \ttt{List<T>}$ contenente tali elementi può essere rappresentata come segue: $$\ttt [ a_1, \ldots, a_n \ttt ]$$
    \end{frameddefn}

    \begin{frameddefn}{Algebra delle liste finite}
        L'\tbf{algebra delle liste finite} è definita come segue: $$(\ttt{List<T>}, \mathrm{empty}, \mathrm{cons})$$ dove i costruttori sono i seguenti: $$\centeredsoe{\funcmap{\mathrm{empty}}{\1}{\ttt{List<T>}}{x}{\ttt{[]}} \\ \funcmap{\mathrm{cons}}{\ttt{List<T>} \times \ttt{T}}{\ttt{List<T>}}{(\ttt [ a_1, \ldots, a_n \ttt ], x)}{\ttt [ a_1, \ldots, a_n , x \ttt ]}}$$
    \end{frameddefn}

    \begin{framedprop}[label={alf induttiva}]{Liste finite induttive}
        L'algebra delle liste finite è induttiva.
    \end{framedprop}

    \begin{proof}
        Si noti che:

        \begin{itemize}
            \item $\mathrm{empty}$ è iniettiva per l'\cref{inj null}
            \item $\forall l, l' \in \ttt{List<T>}, x, x' \in \ttt{T} \quad \mathrm{cons}(l, x) = \mathrm{cons}(l', x') \implies \soe{l}{l = l' \\ x = x'}$ altrimenti $l$ ed $l'$ avrebbero avuto lunghezze diverse, oppure avrebbero contenuto diversi elementi;
            \item $\im(\mathrm{empty}) \cap \im(\mathrm{cons}) = \varnothing$, poiché solo $\mathrm{empty}$ può restituire $\ttt [ \ttt ]$, in quanto $\mathrm{cons}$ restituisce sempre una lista contenente almeno l'elemento fornito in input;
            \item sia $S \subseteq \ttt{List<T>}$ tale da essere chiuso rispetto ad $\mathrm{empty}$ e $\mathrm{cons}$ --- dunque contenente la lista vuota; per assurdo, sia $\ttt{List<T>} - S \neq \varnothing \iff \exists l \in \ttt{List<T>} - S$, ma $\ttt{List<T>}$ è chiuso rispetto a $\mathrm{cons}$, ed in particolare $\exists x \in \ttt{T}, l' \in \ttt{List<T>} \mid \mathrm{cons}(l', x) = l$, ma poichè $l \notin S$, allora necessariamente $l' \notin S$ poiché $S$ è chiuso rispetto a $\mathrm{cons}$; dunque, ripetendo tale ragionamento induttivamente, si ottiene che $S$ è vuoto, ma questo è impossibile poiché $\ttt{[]} \in S$ per chiusura su $\mathrm{empty}$ $\lightning$.
        \end{itemize}

        Dunque, l'algebra delle liste finite risulta essere induttiva.
    \end{proof}

    \begin{framedobs}[label={infinite lists}]{Algebra delle liste infinite}
        Se all'algebra delle liste finite venissero aggiunte anche le liste infinite, l'algebra risultante non sarebbe induttiva, in quanto conterrebbe l'algebra delle liste finite, la quale è induttiva per la \cref{alf induttiva}, e verrebbe dunque contraddetto il terzo assioma della \cref{inductive algebra}.
    \end{framedobs}

    \begin{framedobs}{Concatenazione di liste finite}
        È possibile estendere l'algebra delle liste finite per supportare l'operazione di concatenazione tra liste, come segue: \centeredeq{0.99}{$\funcmap{\mathrm{concat}}{\ttt{List<T>} \times \ttt{List<T>}}{\ttt{List<T>}}{(l, l')}{\soe{ll}{l & l' = \ttt{[]} \\ \mathrm{cons}(\mathrm{concat}(l, t), x) & \exists x \in \ttt T, t \in \ttt{List<T>} \mid l' = \mathrm{cons}(t, x)}}$}
    \end{framedobs}

    \begin{example}[Concatenazioni di liste finite]
        Per concatenare le liste $$\centeredsoe{\ttt [ 1, 2 \ttt ] \\ \ttt [ 3, 4, 5 \ttt ] }$$ è sufficiente applicare la funzione $\mathrm{concat}$, e dunque si ottiene $$\centeredsoe{\mathrm{concat}(\ttt [ 1, 2 \ttt ], \ttt[3, 4, 5 \ttt] ) = \\ = \mathrm{cons}(\mathrm{concat}(\ttt[1, 2\ttt], \ttt[3, 4\ttt]), 5) = \mathrm{cons}(\mathrm{cons}(\mathrm{concat}(\ttt[1, 2\ttt], \ttt[3\ttt]), 4), 5) = \\ = \mathrm{cons}(\mathrm{cons}(\mathrm{cons}(\mathrm{concat}(\ttt[1, 2\ttt], \ttt{[]}), 3), 4), 5) = \mathrm{cons}(\mathrm{cons}(\mathrm{cons}(\ttt[1, 2\ttt], 3), 4), 5) = \\ = \mathrm{cons}(\mathrm{cons}(\ttt[1, 2, 3\ttt], 4), 5) = \mathrm{cons}(\ttt[1, 2, 3, 4\ttt], 5) = \ttt[1, 2, 3, 4, 5\ttt]}$$
    \end{example}

    \subsection{Alberi binari}

    \begin{frameddefn}{Albero binario}
        Un \tbf{albero binario} è una struttura dati che è possibile rappresentare graficamente come segue:

        \begin{figure}[H]
            \centering
            \begin{tikzpicture}[
                    level distance=1cm,
                    level 1/.style={sibling distance=2cm},
                    level 2/.style={sibling distance=1cm}
                ]
                \node {$\circ$}
                    child {node {$\circ$}
                    child {node {$\circ$}}
                    child {node {$\circ$}}
                }
                    child {node {$\circ$}
                };
            \end{tikzpicture}
        \end{figure}

        Il primo nodo, poiché non è figlio di nessuno, è detto \tbf{radice}, e poiché l'albero è \tit{binario}, ogni nodo ha 0 --- nel qual caso è definito \tbf{foglia} --- oppure 2 figli. L'insieme degli alberi binari viene denotato con \ttt{B-tree}.
    \end{frameddefn}

    \begin{frameddefn}{Algebra degli alberi binari finiti}
        L'\tbf{algebra degli alberi binari finiti} è definita come segue: $$(\ttt{B-tree}, \mathrm{leaf}, \mathrm{branch})$$ dove i costruttori sono i seguenti:

        $$\funcmap{\mathrm{leaf}}{\1}{\ttt{B-tree}}{x}{\circ}$$

        \begin{center}
            \begin{tabular}{c c}
                \begin{tabular}{c}$\funcmap{\mathrm{branch}}{\ttt{B-tree} \times \ttt{B-tree}}{\ttt{B-tree}}{(b, b')}{}$\end{tabular}
                &
                \begin{tabular}{c}
                    \begin{tikzpicture}[
                            level distance=1cm,
                            level 1/.style={sibling distance=1cm},
                        ]
                        \node {$\circ$}
                            child {node {$b$}
                        }
                            child {node {$b'$}
                        };
                    \end{tikzpicture}
                \end{tabular}
            \end{tabular}
        \end{center}
    \end{frameddefn}

    \begin{framedprop}{Alberi binari finiti induttivi}
        L'algebra degli alberi binari finiti è induttiva.
    \end{framedprop}

    \begin{proof}
        Omessa.
    \end{proof}

    \begin{framedobs}{Algebra degli alberi binari infiniti}
        Analogamente all'\cref{infinite lists}, l'algebra degli alberi binari finiti ed infiniti non è induttiva.
    \end{framedobs}

    \begin{framedobs}{Nodi di un albero binario finito}
        È possibile estendere l'algebra degli alberi binari finiti per supportare l'operazione per contare i nodi di un albero, come segue: \centeredeq{0.99}{$\funcmap{\mathrm{nodes}}{\ttt{B-tree}}{\N}{b}{\soe{ll}{1 & b = \circ \\ 1 + \mathrm{nodes}(t) + \mathrm{nodes}(t')  & \exists t, t' \in \ttt{B-tree} \mid b = \mathrm{branch}(t, t')}}$}
    \end{framedobs}

    \begin{framedobs}{Foglie di un albero binario finito}
        È possibile estendere l'algebra degli alberi binari finiti per supportare l'operazione per contare le foglie di un albero, come segue: $$\funcmap{\mathrm{leaves}}{\ttt{B-tree}}{\N}{b}{\soe{ll}{1 & b = \circ \\ \mathrm{leaves}(t) + \mathrm{leaves}(t') & \exists t, t' \in \ttt{B-tree} \mid b = \mathrm{branch}(t, t')}}$$
    \end{framedobs}

    \begin{framedthm}{Relazione tra foglie e nodi}
        Ogni albero binario finito, avente $n$ foglie, ha $2n - 1$ nodi.
    \end{framedthm}

    \proofind{
        La seguente dimostrazione procede per \tit{induzione strutturale}, dunque effettuando l'induzione sulla morfologia della struttura dati, e non sul numero $n$ di foglie.
    }{
        Il caso base è costituito dunque da $\circ$, l'albero ottenuto attraverso il costruttore nullario $\mathrm{leaf}$, ed infatti si ha che $$\mathrm{leaves}(\circ) = 1 \implies 2 \cdot 1 - 1 = 1$$ e $\circ$ ha esattamente 1 nodo.
    }{
        Un albero binario finito, avente $n$ foglie, ha $2n - 1$ nodi.
    }{
        Sia $b \in \ttt{B-tree}$ tale che esistano $t, t' \in \ttt{B-tree}$ tali che $\mathrm{branch}(t, t') = b$, e siano $$\soe{l}{\mathrm{leaves}(t) = n \\ \mathrm{leaves}(t') = n'}$$ Si noti che, per ipotesi induttiva, si ha che $$\soe{l}{\mathrm{nodes}(t) = 2n - 1 \\ \mathrm{nodes}(t') = 2n' - 1}$$ ed inoltre, poiché $b = \mathrm{branch}(t, t')$, $b$ ha la forma seguente

        \begin{figure}[H]
            \centering
            \begin{tikzpicture}[
                    level distance=1cm,
                    level 1/.style={sibling distance=1cm},
                ]
                \node {$\circ$}
                    child {node {$t$}
                }
                    child {node {$t'$}
                };
            \end{tikzpicture}

        \end{figure}
        dunque, per definizione di $\mathrm{leaves}$ si ha che $$\mathrm{leaves}(b) = \mathrm{leaves}(t) + \mathrm{leaves}(t') = n + n'$$ e, dalla morfologia di $b$, segue che $$\mathrm{nodes}(b) = \mathrm{nodes}(t) + \mathrm{notes}(t') + 1 = 2n -1 + 2n'-1 + 1 = 2(n + n') - 1$$ ed è quindi verificata la tesi, poiché $$\mathrm{leaves}(b) = n + n' \implies \mathrm{nodes}(b) = 2(n + n') - 1$$
    }
    
    \chapter{Paradigma funzionale}

    \section{Grammatiche}
    
    \subsection{Definizioni}

    \begin{frameddefn}{Grammatica}
        Una \tbf{grammatica} è un insieme di regole che definiscono come manipolare un insieme di stringhe, agendo su elementi sintattici detti \tbf{termini}.
    \end{frameddefn}

    \begin{frameddefn}{Variabili}
        Data una grammatica di $G$, con $\mathrm{Var}$ si indica l'\tbf{insieme delle variabili} di $G$.
    \end{frameddefn}

    \begin{frameddefn}{Valori}
        Data una grammatica, con $\mathrm{Val}$ si indica l'\tbf{insieme dei valori} che ogni termine della grammatica può assumere.
    \end{frameddefn}

    \begin{frameddefn}{Forma di Backus-Naur (BNF)}
        La \tbf{forma di Backus-Naur} (\tit{Backus-Naur Form}) è una notazione utilizzata per descrivere la sintassi di grammatiche, ed è definita come segue: 

        \begin{center}
            \begin{tabular}{rcl}
                $\ttt{symbol}, \ldots, \ttt{symbol}$ & $::=$ & $\ttt{expression} \smid \ldots \smid \ttt{expression}$ \\
            \end{tabular}
        \end{center}

        \begin{itemize}
            \item $\ttt{symbol}$ è una \tit{metavariabile non terminale}, in quanto può essere sostituita con regole definite dalla grammatica;
            \item il simbolo $::=$ indica che ciò che è posto alla sua sinistra deve essere sostituito con ciò che è alla sua destra;
            \item $\ttt{expression}$ è un espressione che verrà usata per rimpiazzare le metavariabili non terminali, attraverso le regole definite dalla grammatica; le \tit{metavarabili} che compongono le espressioni possono essere \tbf{costanti}, \tbf{variabili}, \tbf{termini}, oppure \tbf{espressioni} contenenti combinazioni delle precedenti, presentando eventualmente anche operazioni sintattiche specifiche.
        \end{itemize}
    \end{frameddefn}

    \section{$Exp$: un primo linguaggio}

    \subsection{Definizioni}

    \begin{frameddefn}[label={exp}]{Grammatica $Exp$}
        Sia $Exp$ la seguente grammatica:
        
        \begin{center}
            \begin{tabular}{rcl}
                $M, N$ & $::=$ & $0 \smid 1 \smid \ldots \smid x \smid M + N \smid M * N$ \\
            \end{tabular}
        \end{center}

        essa definisce le regole per utilizzare i numeri in $\N$, ammettendo inoltre le operazioni \und{sintattiche} di somma e prodotto. Dunque, essa è composta da:

        \begin{itemize}
            \item \tit{costanti}: $0, 1, \ldots$
            \item \tit{variabili}: $x$
            \item \tit{termini}: $M$ ed $N$
            \item \tit{espressioni}: $M + N$ e $M * N$ (si noti che anche le precedenti sono espressioni)
        \end{itemize}

        Dunque, segue che $$\centeredsoe{\mathrm{Var} = \{ x \} \\ \mathrm{Val} = \{ 0, 1, \ldots \}}$$
    \end{frameddefn}

    \begin{frameddefn}{Linguaggio di una grammatica}
        Sia $G$ una grammatica; allora, il suo \tbf{linguaggio} è l'insieme delle stringhe che è possibile costruire attraverso le regole di $G$.
    \end{frameddefn}

    \begin{example}[Linguaggio di $Exp$]
        Considerando ad esempio le stringhe $\ttt{"4"}$ e $\ttt{"23"}$, si può ottenere la stringa $$+(\ttt{"4"}, \ttt{"23"}) = \ttt{"4 + 23"}$$ dove la \tit{polish notation} --- alla sinistra dell'uguale --- e la forma sintattica canonica --- alla sua destra --- verranno utilizzate intercambiabilmente, poiché puro \tit{syntactic sugar}.
    \end{example}

    \begin{framedobs}[label={eval}]{Valutazione di $Exp$}
        Si prenda in considerazione la grammatica $Exp$ della \cref{exp}; su di essa, è possibile definire ricorsivamente una funzione $\mathrm{eval}$, in grado di valutare le stringhe che tale grammatica può produrre, come segue: $$\centeredsoe{\mathrm{eval}( 0) = 0 \\ \mathrm{eval}(1) = 1 \\ \vdots \\ \mathrm{eval}(M + N) = \mathrm{eval}(M) + \mathrm{eval}(N) \\ \mathrm{eval}(M * N) = \mathrm{eval}(M) * \mathrm{eval}(N)}$$
    \end{framedobs}

    \begin{framedobs}[label={ambiguity}]{Ambiguità di $Exp$}
        Si prenda in considerazione la grammatica $Exp$ della \cref{exp}; si noti che tale grammatica è ambigua, poichè ad esempio $$+(\ttt{"5"}, *(\ttt{"6"}, \ttt{"7"})) = \ttt{"5 + 6 * 7"} = *(+(\ttt{"5"}, \ttt{"6"}), \ttt{"7"})$$ e da ciò segue anche che $\im(+) \cap \im(*) \neq \varnothing$.
    \end{framedobs}

    \begin{framedobs}{Disambiguazione di $Exp$}
        Si noti che l'ambiguità trattata nell'\cref{ambiguity} non permetterebbe di poter definire la funzione $\mathrm{eval}$, descritta nell'\cref{eval}. Dunque, per risolvere tale ambiguità, a meno di parentesi (che \tit{non} sono definite all'interno della grammatica) o dell'esplicitazione della composizione di funzioni utilizzata, verrà sottintesa la normale precedenza degli operatori aritmetica durante la valutazione delle stringhe.
    \end{framedobs}

    \subsection{Assegnazioni}

    \begin{frameddefn}[label={let}]{Clausola $let$}
        La clausola $let$ verrà utilizzata attraverso la sintassi $$\letin{\ttt{variable}}{\ttt{expression}_1}{\ttt{expression}_2}$$ dove alla variabile $\ttt{variable}$ verrà assegnata l'espressione $\ttt{expression}_1$ \tit{durante la valutazione} di $\ttt{expression}_2$; la variabile $\ttt{variable}$, all'interno di $\ttt{expression}_2$, prende il nome di \tbf{variabile locale}.

        Una variabile alla quale non è stata assegnata nessuna espressione prende il nome di \tbf{variable libera} (\tit{free variable}); una variabile non libera è detta \tbf{variabile legata} (\tit{bound variable}). L'azione di legare o liberare una variabile è detta \tbf{variable binding}.
    \end{frameddefn}
    
    \begin{frameddefn}[label={exp2}]{Estensione di $Exp$}
        Sia $Exp$ la seguente estensione della grammatica presente all'interno della \cref{exp}:

        \begin{center}
            \begin{tabular}{rcl}
                $M, N$ & $::=$ & $k \smid x \smid M + N \smid M * N \smid \letin{x}{M}{N}$ \\
            \end{tabular}
        \end{center}

        In essa, sono presenti:

        \begin{itemize}
            \item \tit{costanti}: indicate con $k$, che sta ad indicare che in $Exp$ è ammessa qualsiasi costante; di fatto, è possibile pensare a $k$ come una funzione definita come segue: $$\funcmap{k}{\N}{Exp}{x}{\ttt{"x"}}$$
            \item \tit{variabili}: $x$
            \item \tit{termini}: $M$ ed $N$
            \item \tit{espressioni}: $M + N$, $M * N$ e $\letin{x}{M}{N}$
        \end{itemize}
    \end{frameddefn}

    \begin{framedobs}{Convenzione per le espressioni}
        Si noti che, d'ora in avanti, le espressioni delle grammatiche presentate non verranno indicate con il \ttt{"virgolettato"}, poiché verrà sottointesa la trasformazione tra i simboli \tit{sintattici} delle grammatiche, e le vere operazioni e/o costanti che rappresentano \tit{semanticamente}.
    \end{framedobs}

    \begin{example}[Clausole $let$]
        Sia $Exp$ la grammatica della \cref{exp2}; un esempio di espressione su $Exp$, che utilizza la clausola $let$ della \cref{let}, è la seguente: $$\letin{x}{3}{(x + 1)}$$ e nel momento in cui viene valutata tale espressione, si ha che $$x = 3 \implies x + 1 = 3 + 1 = 4$$ e dunque il valore dell'espressione è 4.
    \end{example}

    \begin{example}[Variabili libere]
        Sia $Exp$ la grammatica della \cref{exp2}, ed ammettendo la variabile $y$ in essa, si consideri la seguente espressione: $$\letin{x}{3}{(x + y)}$$ in essa, la variabile $x$ è posta pari a 3, ma ad $y$ non è stato assegnato alcuna espressione, e dunque risulta essere una variabile libera.
    \end{example}

    \begin{framedobs}{Ambiguità di $let$}
        Sia $Exp$ la grammatica della \cref{exp2}, e si consideri la sua seguente espressione $$\letin{x}{M}{x + y}$$ per qualche espressione $M \in Exp$, e due variabili $x, y \in \mathrm{Var}$, ammettendo dunque $y$ tra le variabili di $Exp$; si noti che tale espressione è ambigua, poiché potrebbe equivalere a $$(\letin{x}{M}{x}) + y$$ oppure a $$\letin{x}{M}{(x + y)}$$ Per convenzione, all'interno di questi appunti, in assenza di parentesi che descrivano la precedenza degli operatori, si assume la precedenza della seconda espressione mostrata.
    \end{framedobs}

    \begin{framedobs}{Variabili libere di $Exp$}
        Sia $Exp$ la grammatica della \cref{exp2}; su di essa, è possibile definire, ricorsivamente, una funzione in grado di restituire le variabili free di una data espressione, come segue: \centeredeq{0.99}{$\funcmap{\mathrm{free}}{Exp}{\powerset{\left(\mathrm{Var}\right)}}{e}{\soe{ll}{
            \varnothing & \exists \eta \in \N \mid e = k(\eta) \\ 
            \{x\} & \exists x \in \mathrm{Var} \mid e = x \\ 
            \mathrm{free}(M) \cup \mathrm{free}(N) & \exists M, N \in Exp \mid e = M + N \lor e = M * N \\
            \mathrm{free}(M) \cup (\mathrm{free}(N) - \{x\}) & \exists x \in \mathrm{Var}, M, N \in Exp \mid e = (\letin{x}{M}{N})
        }}$}
    \end{framedobs}

    \subsection{Ambienti}
    
    \begin{frameddefn}[label={env}]{Ambiente di una grammatica}
        Data una grammatica tale che $\mathrm{Val}$ sia un insieme finito, un \tbf{ambiente} della grammatica è una funzione della forma $$E: \mathrm{Var} \xrightarrow{fin} \mathrm{Val}$$ che associa dunque una variabile ad un possibile valore che può assumere (la notazione $fin$ indica che $E$ è una funzione \tit{parziale}, dunque non necessariamente definita su tutto il dominio). L'insieme di tutti gli ambienti della grammatica è denotato con $$\mathrm{Env} := \{f \mid f : \mathrm{Var} \xrightarrow{fin} \mathrm{Val} \}$$ In simboli, gli ambienti verranno scritti come insiemi di coppie $(x, k)$ con $x \in \mathrm{Var}, k \in \mathrm{Val}$, che descriveranno la mappa definita dall'ambiente stesso. Si noti che, per un certo ambiente $E \in \mathrm{Env}$, $E(x)$ è indefinito per ogni $x \in \mathrm{Var} - \dom(E)$.
    \end{frameddefn}

    \begin{example}[Ambienti di $Exp$]
        Sia $Exp$ la grammatica della \cref{exp2}; allora, un possibile ambiente di $Exp$, denotato con $E \in \mathrm{Env}$, è il seguente: $$E := \{(z,3), (y, 9) \}$$ ed esso esprime la possibilità che in $Exp$ $z$ possa essere valutato pari a 3, mentre $y$ pari a 9 (tecnicamente, le variabili $z$ ed $y$ andrebbero ammesse all'interno della grammatica, ma d'ora in avanti tale precisazione verrà sottintesa).
    \end{example}

    \begin{frameddefn}{Concatenazione di ambienti}
        Siano $E_1$ ed $E_2$ due ambienti di una grammatica; allora, si definisce \tbf{concatenazione} di $E_1$ ed $E_2$ la seguente funzione $$E_1E_2: \mathrm{Env} \times \mathrm{Env} \to \mathrm{Env} : x \mapsto \soe{ll}{E_2(x) & x \in \dom(E_2) \lor x \in \dom(E_1) \cap \dom(E_2) \\ E_1(x) & x \in \dom(E_1)}$$ dunque, nella concatenazione $E_2$ sovrascrive le tuple che sono presenti anche in $E_1$.
    \end{frameddefn}

    \begin{example}[Concatenazioni di ambienti]
        Sia $Exp$ la grammatica descritta all'interno della \cref{exp2}, e siano $$\centeredsoe{E_1 := \{(z, 3), (y, 9)\} \\ E_2 := \{(z, 4)\}}$$ due suoi ambienti; allora si ha che $$E_1E_2 = \{(z, 3), (y, 9)\}\{(z, 4)\} = \{(z, 4), (y, 9)\}$$
    \end{example}

    \subsection{Semantica operazionale di $Exp$}

    \begin{frameddefn}[label={sem opexp}]{Semantica operazionale di una grammatica}
        Data una grammatica $G$, si definisce \tbf{semantica operazionale} della grammatica una relazione, indicata col simbolo $\leadsto$, definita come segue: $$\leadsto \ \subseteq \mathrm{Env} \times G \times \mathrm{Val}$$
        Un elemento $(E, M, v) \in \ \leadsto$ è detto \tbf{giudizio operazionale}, e viene scritto attraverso il seguente simbolismo: $$\opjud{E}{M}{v}$$ e si legge \curlyquotes{valutando $M$, nell'ambiente $E$, si ottiene $v$}.
    \end{frameddefn}

    \begin{framedprop}[label={exp2 clauses}]{Semantica operazionale di $Exp$}
        Sia $Exp$ la grammatica definita all'interno della \cref{exp2}, e sia $E$ un suo ambiente; allora, si definiscono le seguenti regole operazionali:
        
        \begin{itemize}
            \item \tbf{costanti}: $$[const] \ \opjud{E}{k}{k}$$
            \item \tbf{variabili}: $$\exists v \in \mathrm{Val} \mid E(x) = v \implies [vars] \ \opjud{E}{x}{v}$$
            \item \tbf{somme}: $$\exists v \in \mathrm{Val} \mid v = v' + v'' \implies [plus] \ \dfrac{\opjud{E}{M}{v'} \quad \opjud{E}{N}{v''}}{\opjud{E}{M + N}{v}}$$
            \item \tbf{prodotti}: $$\exists v \in \mathrm{Val} \mid v = v' \cdot v'' \implies [times] \ \dfrac{\opjud{E}{M}{v'} \quad \opjud{E}{N}{v''}}{\opjud{E}{M * N}{v}}$$
            \item \tbf{dichiarazioni ed assegnazioni}: $$[let] \ \dfrac{\opjud{E}{M}{v'} \quad \opjud{E\{(x, v')\}}{N}{v}}{\opjud{E}{\letin{x}{M}{N}}{v}}$$
        \end{itemize}
    \end{framedprop}

    \begin{frameddefn}{Equivalenza operazionale}
        Sia $G$ una grammatica, e siano $M$ ed $N$ due sue espressioni; queste sono dette \tbf{operazionalmente equivalenti}, se è vera la seguente: $$\forall E \in \mathrm{Env}, v \in \mathrm{Val} \quad \opjud{E}{M}{v} \iff \opjud{E}{N}{v}$$ e viene indicato con il simbolismo $$M \sim N$$
    \end{frameddefn}

    \begin{frameddefn}{Albero di valutazione}
        Con \tbf{albero di valutazione} di un'espressione $M$, si definisce l'albero, composto da inferenze logiche, ottenuto valutando $M$.
    \end{frameddefn}

    \begin{framedobs}{Ambiente iniziale}
        Per qualsiasi grammatica --- a meno di specifiche --- si assume che, all'interno di una valutazione, l'ambiente iniziale sia $\varnothing \in \mathrm{Env}$.
    \end{framedobs}

    \begin{example}[Alberi di valutazione su $Exp$]
        Sia $Exp$ la grammatica definita all'interno della \cref{exp2}; allora, l'albero di valutazione dell'espressione $$\letin{x}{3}{x + 4}$$ è il seguente $$\dfrac{\opjud{\varnothing}{3}{3} \quad \dfrac{\opjud{\{(x, 3)\}}{x}{3} \quad \opjud{\{(x,3)\}}{4}{4}}{\opjud{\{(x, 3)\}}{x +4}{7}}}{\opjud{\varnothing}{\letin{x}{3}{x +4}}{7}}$$ e l'espressione è valutabile poiché $x \in \dom(\{(x,1)\}) = \{x\}$.
    \end{example}

    \subsection{Valutazioni e scoping}

    \begin{frameddefn}{Valutazione eager}
        Data una grammatica, la \tbf{valutazione eager} valuta una data espressione della grammatica non appena questa viene legata ad una variabile. In simboli, la valutazione eager verrà indicata con il pedice $\mathrm{E}$.
    \end{frameddefn}

    \begin{frameddefn}{Valutazione lazy}
        Data una grammatica, la \tbf{valutazione lazy} valuta una data espressione della grammatica solo quando il suo valore viene richiesto da un'altra espressione. In simboli, la valutazione lazy verrà indicata con il pedice $\mathrm{L}$.
    \end{frameddefn}

    \begin{frameddefn}{Scoping statico}
        Data una grammatica, la valutazione a \tbf{scoping statico} (detto anche \tit{lexical scope}) valuta una data espressione della grammatica utilizzando l'ambiente definito in tempo di interpretazione. In simboli, lo scoping statico verrà indicato con il pedice $\mathrm{S}$.
    \end{frameddefn}

    \begin{frameddefn}{Scoping dinamico}
        Data una grammatica, la valutazione a \tbf{scoping dinamico} valuta una data espressione della grammatica utilizzando l'ambiente definito in tempo di valutazione. In simboli, lo scoping dinamico verrà indicato con il pedice $\mathrm{D}$.
    \end{frameddefn}

    \begin{frameddefn}[label={equiv lang}]{Equivalenza di semantiche operazionali}
        Data una grammatica, due sue semantiche operazionali sono dette \tbf{equivalenti} se, presa una qualunque espressione di $G$, quando questa viene valutata attraverso le due semantiche, produce lo stesso risultato.

        In simboli, data una grammatica $G$, e due sue semantiche operazionali $\mathrm{A}$ e $\mathrm{B}$, se queste sono equivalenti, la loro equivalenza viene denotata con il seguente simbolismo: $$G_\mathrm{A} \equiv G_\mathrm{B}$$
    \end{frameddefn}

    \begin{framedlem}{$Exp_\mathrm{ES}$ e $Exp_\mathrm{ED}$}
        Sia $Exp$ la grammatica definita all'interno della \cref{exp2}, avente le clausole definite nell'\cref{exp2 clauses}; allora, si ha che $$Exp_\mathrm{ES} \equiv Exp_\mathrm{ED}$$
    \end{framedlem}

    \begin{proof}
        Omessa.
    \end{proof}

    \begin{example}[$Exp_\mathrm{E}$]
        \label{eager2}
        Sia $Exp$ la grammatica definita nella \cref{exp2}, e si consideri la seguente espressione: $$\letin{x}{3}{(\letin{y}{x}{(\letin{x}{7}{y + x})})}$$ essa, valutata attraverso valutazione eager, produce il seguente albero di derivazione: \centeredeq{0.99}{$\dfrac{\opjud{\varnothing}{3}{3} \quad \dfrac{\opjud{\{(x, 3)\}}{x}{3} \quad \dfrac{\opjud{\{(x,3),(y,3)\}}{7}{7} \quad \dfrac{\opjud{\{(x,3),(y,3)\}\{(x,7)\}}{y}{3} \quad \opjud{\{(x,3),(y,3)\}\{(x,7)\}}{x}{7}}{\opjud{\{(x,3),(y,3)\}\{(x,7)\}}{y+x}{10}}}{\opjud{\{(x, 3),(y, 3)\}}{\letin{x}{7}{y + x}}{10}}}{\opjud{\{(x, 3)\}}{\letin{y}{x}{(\letin{x}{7}{y + x})}}{10}}}{\opjud{\varnothing}{\letin{x}{3}{(\letin{y}{x}{(\letin{x}{7}{y + x})})}}{10}}$}
    \end{example}

    \begin{framedprop}[label={exp ld}]{$Exp_\mathrm{LD}$}
        Sia $Exp$ la grammatica definita nella \cref{exp2}; per poter valutare le sue espressioni in maniera lazy dinamica, è necessario ridefinire alcune regole di inferenza definite all'interno dell'\cref{exp2 clauses}:

        \begin{itemize}
            \item l'insieme degli ambienti di $Exp$ viene ridefinito come segue: $$\mathrm{Env} := \{f \mid f :\mathrm{Var} \xrightarrow{fin} \mathrm{Val} \cup Exp\}$$
            \item \tbf{variabili}: $$x \in \dom(E) \land M := E(x) \implies [vars] \ \dfrac{\opjud{E}{M}{v}}{\opjud{E}{x}{v}}$$
            \item \tbf{assegnazioni}: $$[let] \ \dfrac{\opjud{E\{(x, M)\}}{N}{v}}{\opjud{E}{\letin{x}{M}{N}}{v}}$$
        \end{itemize}
    \end{framedprop}

    \begin{framedprop}[label={exp ls}, breakable]{$Exp_\mathrm{LS}$}
        Sia $Exp$ la grammatica definita all'interno della \cref{exp2}; per poter valutare le sue espressioni in maniera lazy statica, è necessario ridefinire alcune regole di inferenza definite all'interno dell'\cref{exp2 clauses}:

        \begin{itemize}
            \item l'insieme degli ambienti di $Exp$ viene ridefinito come segue: $$\mathrm{Env} := \{f \mid f: \mathrm{Var} \xrightarrow{fin} \mathrm{Val} \cup (Exp \times \mathrm{Env}) \}$$
            \item \tbf{variabili}: $$x \in \dom(E) \land (M, E') := E(x) \implies [vars] \ \dfrac{\opjud{E'}{M}{v}}{\opjud{E}{x}{v}}$$
            \item \tbf{assegnazioni} $$[let] \ \dfrac{\opjud{E\{(x, (M, E))\}}{N}{v}}{\opjud{E}{\letin{x}{M}{N}}{v}}$$
        \end{itemize}
    \end{framedprop}

    \begin{framedlem}[label={exp ls != exp ld}]{$Exp_\mathrm{LS}$ e $Exp_\mathrm{LD}$}
        Sia $Exp$ la grammatica definita nella \cref{exp2}; allora, si ha che $$Exp_\mathrm{LS} \not\equiv Exp_\mathrm{LD}$$
    \end{framedlem}

    \begin{proof}
        Si consideri l'espressione definita nell'\cref{eager2}; essa, valutata attraverso valutazione lazy dinamica, produce il seguente albero di derivazione: $$\dfrac{\dfrac{\dfrac{\dfrac{\dfrac{\dfrac{\opjud{\{(x,3),(y,x)\}\{(x,7)\}}{7}{7}}{\opjud{\{(x,3),(y,x)\}\{(x,7)\}}{x}{7}}}{\opjud{\{(x,3),(y,x)\}\{(x,7)\}}{y}{7}} \quad \dfrac{\opjud{\{(x,3),(y,x)\}\{(x,7)\}}{7}{7}}{\opjud{\{(x,3),(y,x)\}\{(x,7)\}}{x}{7}}}{\opjud{\{(x,3),(y,x)\}\{(x,7)\}}{y+x}{14}}}{\opjud{\{(x,3),(y,x)\}}{\letin{x}{7}{y+x}}{14}}}{\opjud{\{(x,3)\}}{\letin{y}{x}{(\letin{x}{7}{y+x})}}{14}}}{\opjud{\varnothing}{\letin{x}{3}{(\letin{y}{x}{(\letin{x}{7}{y+x})})}}{14}}$$

        Differentemente, valutando tale espressione attraverso valutazione lazy statica, produce il seguente albero di derivazione: $$\dfrac{\dfrac{\dfrac{\dfrac{\dfrac{\dfrac{\opjud{\varnothing}{3}{3}}{\opjud{E}{x}{3}}}{\opjud{E''}{y}{3}} \quad \dfrac{\opjud{E'}{7}{7}}{\opjud{E''}{x}{7}}}{\opjud{E'\{(x,(7,E'))\}}{y+x}{10}}}{\opjud{E\{(y,(x, E))\}}{\letin{x}{7}{y+x}}{10}}}{\opjud{\{(x,(3,\varnothing))\}}{\letin{y}{x}{(\letin{x}{7}{y+x})}}{10}}}{\opjud{\varnothing}{\letin{x}{3}{(\letin{y}{x}{(\letin{x}{7}{y+x})})}}{10}}$$ dove $$\centeredsoe{E := \{(x,(3,\varnothing))\} \\ E' := E\{(y,(x,E))\} \\ E'' := E'\{(x,(7,E'))\}}$$

        Allora, poiché le due valutazioni producono risultati differenti, per la \cref{equiv lang}, segue la tesi.
    \end{proof}

    \section{$Fun$: un linguaggio funzionale}

    \subsection{Definizioni}

    \begin{frameddefn}[label={fn}]{Clausola $fn$}
        La clausola $fn$ verrà utilizzata attraverso la sintassi $$\fn{\ttt{variable}}{\ttt{expression}}$$ che restituisce una funzione avente come parametro $\ttt{variable}$, il cui valore sarà utilizzato per valutare $\ttt{expression}$.
    \end{frameddefn}

    \begin{frameddefn}{Applicazione}
        La clausola di applicazione verrà utilizzata attraverso la sintassi $$\ttt{expression} \ \ttt{expression}$$ Si noti che un'espressione $MNL$ applica prima $M$ ad $N$, e poi $MN$ ad $L$, dunque la precedenza è da sinistra verso destra, ovvero $(MN)L$.
    \end{frameddefn}

    \begin{frameddefn}[label={fun}]{Grammatica $Fun$}
        Sia $Fun$ la seguente estensione della grammatica $Exp$, definita all'interno della \cref{exp2}:

        \begin{center}
            \begin{tabular}{rcl}
                $M, N$ & $::=$ & $k \smid x \smid M + N \smid M * N \smid \letin{x}{M}{N} \smid \fn{x}{M} \smid MN$ \\
            \end{tabular}
        \end{center}
    \end{frameddefn}

    \begin{example}[Funzioni come argomenti]
        Sia la seguente $$(\fn{x}{x +1})7$$ un'espressione di $Fun$; essa, poiché applica la funzione $\fn{x}{x+1}$ all'espressione 7, viene valutata a $$x = 7 \implies x + 1= 7 + 1 = 8$$
    \end{example}

    \begin{example}[Espressioni su $Fun$]
        \label{expr fun}
        Sia la seguente $$(\fn{x}{x3})(\fn{x}{x+1})$$ un'espressione di $Fun$; essa, una volta valutata, applica la funzione $\fn{x}{x+1}$ all'espressione 3, e dunque il suo valore è pari a $$x = 3 \implies x + 1 = 3 + 1 = 4$$
    \end{example}

    \begin{frameddefn}{Curryficazione}
        Si consideri la clausola $fn$ della \cref{fn}; è possibile definirne una notazione contratta, che prende il nome di \tit{curryficazione}, ed è definita come segue: $$\fn{x_1x_2 \ldots x_n}{M} \iff \fn{x_1}{(\fn{x_2}{\ldots (\fn{x_n}{M}) \ldots})}$$ Il processo inverso prende il nome di \tit{uncurryficazione}.
    \end{frameddefn}

    \begin{example}[Curryficazioni]
        Sia la seguente $$(\fn{xy}{yx})7(\fn{x}{x+1})$$ un'espressione di $Fun$; una volta effettuata l'uncurryficazione, si ottiene la seguente espressione: $$(\fn{x}{\fn{y}{yx}})7(\fn{x}{x+1})$$ che, una volta valutata, diventa $$(\fn{y}{y7})(\fn{x}{x+1})$$ e dunque, analogamente all'\cref{expr fun}, il risultato è $$x= 7 \implies x+1 = 7 + 1= 8$$
    \end{example}

    \begin{framedobs}{Significato della curryficazione}
        Si noti che la curryficazione \tit{ha significato}, in quanto è possibile considerare la seguente funzione, la quale restituisce la somma di due costanti $$\fn{x}{\fn{y}{x + y}}$$ come se fosse una \tit{funzione a due argomenti}, poiché per utilizzarla sarà necessario fornire 2 interi, come nel seguente esempio: $$(\fn{x}{\fn{y}{x + y}}) \ 5 \ 7 \longrightarrow (\fn{y}{5 + y})7 \longrightarrow 5 + 7 \longrightarrow 12$$ Di conseguenza, la versione curryficata della funzione presentata, ovvero $$\fn{x}{\fn{y}{x + y}} \iff \fn{xy}{x + y}$$ può essere interpretata come una funzione che lavora con 2 argomenti.
    \end{framedobs}

    \subsection{Semantica operazionale di $Fun$}

    \begin{framedprop}{$Fun_\mathrm{ED}$}
        Sia $Fun$ la grammatica definita nella \cref{fun}; per poter valutare le sue espressioni in maniera eager dinamica, è necessario estenderne le regole di inferenza (assumento che erediti le regole di $Exp_\mathrm{ED}$ definite nella \cref{exp2 clauses}):

        \begin{itemize}
            \item l'insieme degli ambienti di $Fun$ viene definito come segue: $$\mathrm{Env} := \{f \mid f : \mathrm{Var} \xrightarrow{fin} \mathrm{Val}\}$$
            \item l'insieme dei valori di $Fun$ viene ridefinito come segue: $$\mathrm{Val} := \{  0,  1 , \ldots \} \cup (\mathrm{Var} \times Fun)$$                   \item \tbf{funzioni}: $$[fn] \ \opjud{E}{\fn{x}{M}}{(x,M)}$$
            \item \tbf{applicazioni}: $$[appl] \ \dfrac{\opjud{E}{M}{(x,L)} \quad \opjud{E}{N}{v'} \quad \opjud{E\{(x,v')\}}{L}{v}}{\opjud{E}{MN}{v}}$$
        \end{itemize}
    \end{framedprop}

    \begin{framedprop}[breakable]{$Fun_\mathrm{ES}$}
        Sia $Fun$ la grammatica definita nella \cref{fun}; per poter valutare le sue espressioni in maniera eager statica, è necessario estenderne le regole di inferenza (assumendo che erediti le regole di $Exp_\mathrm{ES}$ definite nella \cref{exp2 clauses}):

        \begin{itemize}
            \item l'insieme degli ambienti di $Fun$ viene definito come segue: $$\mathrm{Env} := \{f \mid f : \mathrm{Var} \xrightarrow{fin} \mathrm{Val}\}$$
            \item l'insieme dei valori di $Fun$ viene ridefinito come segue: $$\mathrm{Val} := \{  0, 1, \ldots \} \cup (\mathrm{Var} \times Fun \times \mathrm{Env})$$
            \item \tbf{funzioni}: $$[fn] \ \opjud{E}{\fn{x}{M}}{(x,M,E)}$$
            \item \tbf{applicazioni}: $$[appl] \ \dfrac{\opjud{E}{M}{(x, L, E')} \quad \opjud{E}{N}{v'} \quad \opjud{E'\{(x,v')\}}{L}{v}}{\opjud{E}{MN}{v}}$$
        \end{itemize}
    \end{framedprop}

    \begin{framedlem}[label={fun lemma pt1}]{$Fun_\mathrm{ES}$ e $Fun_\mathrm{ED}$}
        Sia $Fun$ la grammatica definita nella \cref{fun}; allora, si ha che $$Fun_\mathrm{ES} \not\equiv Fun_\mathrm{ED}$$
    \end{framedlem}

    \begin{proof}
        Si consideri la seguente espressione $$\letin{x}{7}{((\fn{y}{\letin{x}{3}{yx}})(\fn{z}{x}))}$$ definita sulla grammatica $Fun$; essa, valutata attraverso valutazione eager dinamica, produce il seguente albero di derivazione: $$(*) \quad \dfrac{\opjud{E'}{3}{3} \quad \dfrac{\opjud{E''}{y}{(z,x)} \quad \opjud{E''}{x}{3} \quad \opjud{E''\{(z,3)\}}{x}{3}}{\opjud{E'\{(x,3)\}}{yx}{3}}}{\opjud{E\{(y,(z,x))\}}{\letin{x}{3}{yx}}{3}}$$ \centeredeq{0.99}{$\dfrac{\opjud{\varnothing}{7}{7} \quad \dfrac{\opjud{E}{\fn{y}{\letin{x}{3}{yx}}}{(y, \letin{x}{3}{yx})} \quad \opjud{E}{\fn{z}{x}}{(z,x)} \quad (*)}{\opjud{\{(x,7)\}}{((\fn{y}{\letin{x}{3}{yx}})(\fn{z}{x}))}{3}}}{\opjud{\varnothing}{\letin{x}{7}{((\fn{y}{\letin{x}{3}{yx}})(\fn{z}{x}))}}{3}}$}

        dove $$\centeredsoe{E := \{(x,7)\} \\ E' := E\{(y,(z,x))\} \\ E'' := E'\{(x,3)\}}$$

        Differentemente, valutando tale espressione attraverso valutazione eager statica, produce il seguente albero di derivazione: $$(*) \quad \dfrac{\opjud{E'}{3}{3} \quad \dfrac{\opjud{E''}{y}{(z,x,E)} \quad \opjud{E''}{x}{3} \quad \opjud{E\{(z,3)\}}{x}{7}}{\opjud{E'\{(x,3)\}}{yx}{7}}}{\opjud{E\{(y,(z,x,E))\}}{\letin{x}{3}{yx}}{7}}$$ \centeredeq{0.99}{$\dfrac{\opjud{\varnothing}{7}{7} \quad \dfrac{\opjud{E}{\fn{y}{\letin{x}{3}{yx}}}{((y,\letin{x}{3}{yx}),E)} \quad \opjud{E}{\fn{z}{x}}{(z,x,E)} \quad (*)}{\opjud{\{(x,7)\}}{(\fn{y}{\letin{x}{3}{yx}})(\fn{z}{x})}{7}}}{\opjud{\varnothing}{\letin{x}{7}{((\fn{y}{\letin{x}{3}{yx}})(\fn{z}{x}))}}{7}}$} dove $$\centeredsoe{E: =\{(x,7)\} \\ E' := E\{(y,(z,x,E))\} \\ E'' := E'\{(x,3)\}}$$

        Allora, poiché le due valutazioni producono risultati differenti, per la \cref{equiv lang}, segue la tesi.
    \end{proof}

    \begin{framedprop}[breakable]{$Fun_\mathrm{LD}$}
        Sia $Fun$ la grammatica definita nella \cref{fun}; per poter valutare le sue espressioni in maniera lazy dinamica, è necessario estenderne regole di inferenza (assumendo che erediti le regole di $Exp_\mathrm{LD}$ definite nella \cref{exp ld}):

        \begin{itemize}
            \item l'insieme degli ambienti di $Fun$ viene ridefinito come segue: $$\mathrm{Env} := \{ f \mid f: \mathrm{Var} \xrightarrow{fin} \mathrm{Val} \cup Fun \}$$
            \item l'insieme dei valori di $Fun$ viene ridefinito come segue: $$\mathrm{Val} := \{  0, 1, \ldots \} \cup (\mathrm{Var} \times Fun)$$
            \item \tbf{funzioni}: $$[fn] \ \opjud{E}{\fn{x}{M}}{(x,M)}$$
            \item \tbf{applicazioni}: $$[appl] \ \dfrac{\opjud{E}{M}{(x,L)} \quad \opjud{E\{(x,N)\}}{L}{v}}{\opjud{E}{MN}{v}}$$
        \end{itemize}
    \end{framedprop}

    \begin{framedprop}{$Fun_\mathrm{LS}$}
        Sia $Fun$ la grammatica definita nella \cref{fun}; per poter valutare le sue espressioni in maniera lazy statica, è necessario estenderne le regole di inferenza (assumendo che erediti le regole di $Exp_\mathrm{LS}$ definite nella \cref{exp ls}):

        \begin{itemize}
            \item l'insieme degli ambienti di $Fun$ viene ridefinito come segue: $$\mathrm{Env} := \{f \mid f :\mathrm{Var} \xrightarrow{fin} \mathrm{Val} \cup (Fun \times \mathrm{Env})\}$$
            \item l'insieme dei valori di $Fun$ viene ridefinito come segue: $$\mathrm{Val} := \{ 0, 1, \ldots\} \cup (\mathrm{Var} \times Fun \times \mathrm{Env})$$
            \item \tbf{funzioni}: $$[fn] \ \opjud{E}{\fn{x}{M}}{(x,M,E)}$$
            \item \tbf{applicazioni}: $$[appl] \ \dfrac{\opjud{E}{M}{(x,L,E')} \quad \opjud{E'\{(x,(N,E))\}}{L}{v}}{\opjud{E}{MN}{v}}$$
        \end{itemize}
    \end{framedprop}

    \begin{framedlem}[label={fun lemma pt2}]{$Fun_\mathrm{LS}$ e $Fun_\mathrm{LD}$}
        Sia $Fun$ la grammatica definita nella \cref{fun}; allora, si ha che $$Fun_\mathrm{LS} \not\equiv Fun_\mathrm{LD}$$
    \end{framedlem}

    \begin{proof}
        Poiché $Fun_\mathrm{LS}$ e $Fun_\mathrm{LD}$ ereditano le regole di $Exp_\mathrm{LS}$ ed $Exp_\mathrm{LD}$ rispettivamente, la tesi segue per dimostrazione analoga alla dimostrazione del \cref{exp ls != exp ld}.
    \end{proof}

    \begin{frameddefn}[label={omega}]{Espressione $\omega$}
        Data una grammatica, l'\tbf{espressione $\omega$} è un'espressione composta dalla più piccola funzione che entra in ricorsione infinita senza chiamare sé stessa.
    \end{frameddefn}

    \begin{example}[Espressione $\omega$ di $Fun$]
        \label{omega fun}
        Sia $Fun$ la grammatica definita all'interno della \cref{fun}; allora, una sua espressione $\omega$ è la seguente: $$\omega := (\fn{x}{xx})(\fn{x}{xx})$$ Essa risulta essere un'espressione $\omega$ per $Fun$, poiché la sua valutazione entra in ricorsione infinita indipendentemente dalla semantica scelta.
    \end{example}

    \begin{framedlem}{Semantiche di $Fun$}
        Sia $Fun$ la grammatica definita nella \cref{fun}; allora, si ha che $$Fun_\mathrm{LD} \not\equiv Fun_\mathrm{ED} \not\equiv Fun_\mathrm{ES} \not\equiv Fun_\mathrm{LS}$$
    \end{framedlem}
    
    \begin{proof}
        Si noti che:

        \begin{itemize}
            \item $Fun_\mathrm{ED} \not\equiv Fun_\mathrm{ES}$ per il \cref{fun lemma pt1}
            \item $Fun_\mathrm{LS} \not\equiv Fun_\mathrm{LD}$ per il \cref{fun lemma pt2}
        \end{itemize}

        mentre, per quanto riguarda $Fun_\mathrm{ED} \not\equiv Fun_\mathrm{LD}$ e $Fun_\mathrm{ES} \not\equiv Fun_\mathrm{LS}$, si prenda l'espressione $\omega$ di $Fun$, presentata all'interno dell'\cref{omega fun}, e si consideri la seguente espressione $$\letin{x}{\omega}{69} \footnote{Nice.}$$ questa, quando valutata in maniera eager --- indipendentemente dallo scoping --- richiederebbe di valutare immediatamente l'espressione $\omega$, la quale è invalutabile per definizione; mentre, quando valutata in maniera lazy --- indipendentemente dallo scoping --- rimanderebbe il calcolo dell'espressione $\omega$, restituendo 69 come risultato. Dunque, poiché si ottengono risultati diversi a seconda della semantica utilizzata per valutare tale espressione, segue la tesi.
    \end{proof}

    \begin{framedobs}{Variabili libere di $Fun$}
        Sia $Fun$ la grammatica della \cref{fun}; su di essa, è possibile definire, ricorsivamente, una funzione in grado di restituire le variabili free di una data espressione, come segue: \centeredeq{0.99}{$\funcmap{\mathrm{free}}{Fun}{\powerset{\left(\mathrm{Var}\right)}}{e}{\soe{ll}{
            \varnothing & \exists \eta \in \N \mid e = k(\eta) \\ 
            \{x\} & \exists x \in \mathrm{Var} \mid e = x \\ 
            \mathrm{free}(M) \cup \mathrm{free}(N) & \exists M, N \in Fun \mid e = M + N \lor e = M * N \\
            \mathrm{free}(M) \cup (\mathrm{free}(N) - \{x\}) & \exists x \in \mathrm{Var}, M, N \in Fun \mid e = (\letin{x}{M}{N}) \\
            \mathrm{free}(M) - \{x\} & \exists x \in \mathrm{Var} , M \in Fun \mid e = (\fn{x}{M}) \\
            \mathrm{free}(M) \cup \mathrm{free}(N) & \exists M,N \in Fun \mid e = (MN)
        }}$}
    \end{framedobs}

    \section{Lambda calcolo}

    \subsection{Numeri di Church}

    \begin{frameddefn}{Numeri di Church}
        La \tbf{rappresentazione di Church dei numeri naturali}, denotata con $\N_\lambda$, è la seguente:
        \begin{itemize}
            \item $0_\lambda := \fn{x}{\fn{y}{y}} \iff \fn{xy}{y}$
            \item $\mathrm{succ}_\lambda := \fn{z}{(\fn{x}{\fn{y}{z x (x y)})}} \iff \fn{zxy}{zx(xy)}$
        \end{itemize}
    \end{frameddefn}

    \begin{example}[$1_\lambda$ di Church]
        \label{1 church}
        Per calcolare l'$1_\lambda \in \N_\lambda$ di Church, è sufficiente valutare $\mathrm{succ}_\lambda(0_\lambda)$, e dunque $$\centeredsoe{(\fn{zxy}{zx(xy)})(\fn{xy}{y}) \longrightarrow \fn{xy}{(\fn{xy}{y})x(xy)} \longrightarrow \\ \longrightarrow \fn{xy}{(\fn{y}{y})(xy)} \longrightarrow \fn{xy}{xy} =: 1_\lambda}$$
    \end{example}

    \begin{example}[$2_\lambda$ di Church]
        \label{2 church}
        Per calcolare il $2_\lambda \in \N_\lambda$ di Church, è sufficiente valutare $\mathrm{succ}_\lambda(1_\lambda)$, e dunque $$\centeredsoe{(\fn{zxy}{zx(xy)})(\fn{xy}{xy}) \longrightarrow \fn{xy}{(\fn{xy}{xy})x(xy)} \longrightarrow \\ \longrightarrow \fn{xy}{(\fn{y}{xy})(xy)} \longrightarrow \fn{xy}{xxy} =: 2_\lambda}$$
    \end{example}

    \begin{framedlem}{Algebra dei numeri di Church}
        Si consideri l'algebra dei numeri di Church, definita come $(\N_\lambda, \mathrm{zero}_\lambda, \mathrm{succ}_\lambda)$, dove $$\funcmap{\mathrm{zero}_\lambda}{\1}{\N_\lambda}{x}{0_\lambda}$$ Essa è un'algebra induttiva.
    \end{framedlem}

    \begin{proof}
        Omessa.
    \end{proof}

    \begin{framedobs}{Significato di $\N_\lambda$}
        Si considerino l'\cref{1 church} e l'\cref{2 church}, e si noti che $$\centeredsoe{0_\lambda := \fn{xy}{y} \\ 1_\lambda := \fn{xy}{xy} \\ 2_\lambda :=\fn{xy}{x(xy)} \\ \vdots}$$ dunque, la corrispondenza tra $\N$ e $\N_\lambda$ è data dal \tit{numero di applicazioni effettuate} ad una qualche variabile. Infatti è possibile costruire il seguente isomorfismo tra le algebre $(\N, \mathrm{zero}, \mathrm{succ})$ e $(\N_\lambda, \mathrm{zero}_\lambda, \mathrm{succ}_\lambda)$: $$\funcmap{\varphi}{\N}{\N_\lambda}{n}{\fn{xy}{\underbrace{x \cdots (x}_{n \ \mathrm{volte}}y)}}$$ dove $x$ è dunque una funzione, che può essere applicata ad una certa variabile $y$.
    \end{framedobs}

    \begin{framedprop}{Funzione $\mathrm{eval}_\lambda$}
        È possibile definire una funzione che, dato un numero di Church, restituisce il corrispondente numero naturale, come segue: $$\mathrm{eval}_\lambda := \fn{z}{z (\fn{x}{x+1}) 0}$$ poiché applica la funzione $\mathrm{succ}_{\N}$ esattamente $z \in \N_\lambda$ volte a 0.
    \end{framedprop}

    \begin{example}[Corrispondenze tra $\N_\lambda$ e $\N$]
        Per valutare $\mathrm{eval}_\lambda(1_\lambda)$ è necessario svolgere i seguenti calcoli: $$\centeredsoe{(\fn{z}{z (\fn{x}{x+1})0})(\fn{xy}{xy}) \longrightarrow (\fn{xy}{xy})(\fn{x}{x+1})0 \longrightarrow \\ \longrightarrow (\fn{y}{(\fn{x}{x+1})y})0 \longrightarrow (\fn{x}{x+1})0 \longrightarrow 1}$$
    \end{example}

    \begin{framedprop}{Operazione $\mathrm{sum}_\lambda$}
        Si consideri l'algebra dei numeri di Church; su di essa, è possibile definire l'operazione di somma, come segue: $$\mathrm{sum}_\lambda := \fn{z}{\fn{w}{(\fn{x}{\fn{y}{z x (w x y)}})}} \iff \fn{zwxy}{zx(wxy)}$$ poiché alla variabile $y$ viene prima applicata $x$ esattamente $w \in \N_\lambda$ volte, e a ciò viene applicato $x$ altre $z \in \N_\lambda$ volte. Inoltre, è possibile fornire una definizione altenrativa della funzione, come segue: $$\mathrm{sum}_\lambda := \fn{z}{\fn{w}{z \ \mathrm{succ}_\lambda \ w}} \iff \fn{zw}{z \ \mathrm{succ}_\lambda \ w}$$
    \end{framedprop}

    \begin{example}[Somme in $\N_\lambda$]
        Per calcolare $\mathrm{sum}_\lambda(2_\lambda, 1_\lambda)$ è necessario svolgere i seguenti calcoli: $$\centeredsoe{(\fn{zwxy}{zx(wxy)})(\fn{xy}{x(xy)})(\fn{xy}{xy}) \longrightarrow \\ \longrightarrow (\fn{wxy}{(\fn{xy}{x(xy)})x(wxy)})(\fn{xy}{xy}) \longrightarrow \\ \longrightarrow (\fn{wxy}{(\fn{y}{x(xy)})(wxy)})(\fn{xy}{xy}) \longrightarrow \\ \longrightarrow (\fn{wxy}{x(x(wxy))})(\fn{xy}{xy}) \longrightarrow \fn{xy}{x(x((\fn{xy}{xy})xy))} \longrightarrow \\ \longrightarrow \fn{xy}{x(x((\fn{y}{xy})y))} \longrightarrow \fn{xy}{x(x(xy))} =: 3_\lambda}$$
    \end{example}

    \begin{framedprop}{Operazione $\mathrm{prod}_\lambda$}
        Si consideri l'algebra dei numeri di Church; su di essa, è possibile definire l'operazione di prodotto, come segue: $$\mathrm{prod}_\lambda := \fn{z}{\fn{w}{(\fn{x}{\fn{y}{z(wx)y}})}} \iff \fn{zwxy}{z(wx)y}$$ poiché alla variabile $y$ viene applicata la funzione $z(wx)$, che equivale alla funzione $wx$ composta su sé stessa $z$ volte --- con $z, w \in \N_\lambda$. Inoltre, è possibile fornire una definizione altenrativa della funzione, come segue: $$\mathrm{prod}_\lambda := \fn{z}{\fn{w}{z (\mathrm{sum}_\lambda \ w)0_\lambda}} \iff \fn{zw}{z(\mathrm{sum}_\lambda \ w)0_\lambda}$$
    \end{framedprop}

    \begin{framedprop}{Operazione $\mathrm{power}_\lambda$}
        Si consideri l'algebra dei numeri di Church; su di essa, è possibile definire l'operazione di elevamento a potenza, come segue: $$\mathrm{power}_\lambda := \fn{z}{\fn{w}{wz}}$$
    \end{framedprop}

    \subsection{Logica booleana di Church}

    \begin{frameddefn}{Logica booleana di Church}
        La \tbf{rappresentazione di Church della logica booleana}, denotata con $\mathbb{B}_\lambda$, è la seguente

        \begin{itemize}
            \item $\mathrm{true}_\lambda := \fn{x}{\fn{y}{x}} \iff \fn{xy}{x}$
            \item $\mathrm{false}_\lambda := \fn{x}{\fn{y}{y}} \iff \fn{xy}{y}$
        \end{itemize}
    \end{frameddefn}

    \begin{framedprop}{Funzione $\mathrm{evalBool}_\lambda$}
        Si consideri la grammatica definita all'interno della \cref{fun}; è possibile estenderla affinché includa anche i valori booleani $true$ e $false$. Dunque, è possibile definire una funzione che, dato un booleano di Church, restituisce il corrispondente valore booleano, come segue: $$\mathrm{evalBool}_\lambda := \fn{z}{z \ true \ false}$$
    \end{framedprop}

    \begin{example}[Valutazione di $\mathrm{true}_\lambda$]
        Per valutare $\mathrm{evalBool}_\lambda(\mathrm{true}_\lambda)$, è sufficiente svolgere i seguenti calcoli: $$\centeredsoe{(\fn{z}{z \ true \ false})(\fn{xy}{x}) \longrightarrow (\fn{xy}{x})true \ false \longrightarrow \\ \longrightarrow (\fn{y}{true})false \longrightarrow true}$$
    \end{example}

    \begin{framedprop}[label={ite}]{Operazione $\mathrm{ite}_\lambda$}
        Si consideri l'algebra dei booleani di Church; su di essa, è possibile definire l'operazione logica \tit{if-then-else}, come segue: $$\mathrm{ite}_\lambda := \fn{z}{\fn{u}{\fn{v}{zuv}}} \iff \fn{zuv}{zuv}$$
    \end{framedprop}

    \begin{framedprop}{Operazione $\mathrm{if}_\lambda$}
        Si consideri l'algebra dei booleani di Church; su di essa, è possibile definire l'operazione logica \tit{if}, come segue: $$\mathrm{if}_\lambda := \fn{z}{\fn{u}{z \ u \ \mathrm{true}_\lambda}} \iff \fn{zu}{z \ u \ \mathrm{true}_\lambda}$$
    \end{framedprop}

    \begin{framedprop}{Operazione $\mathrm{not}_\lambda$}
        Si consideri l'algebra dei booleani di Church; su di essa, è possibile definire l'operazione logica di negazione come segue: $$\mathrm{not}_\lambda := \fn{z}{(\fn{x}\fn{y}{zyx})} \iff \fn{zxy}{zyx}$$ Si noti che l'operazione è simile all'operazione $\mathrm{ite}_\lambda$ definita nella \cref{ite}, poiché è possibile interpretarla come l'inverso dell'operazione \tit{if-then-else}.
    \end{framedprop}

    \begin{framedprop}{Operazione $\mathrm{or}_\lambda$}
        Si consideri l'algebra dei booleani di Church; su di essa, è possibile definire l'operazione logica di $or$, come segue: $$\mathrm{or}_\lambda := \fn{z}{\fn{w}{\mathrm{if}_\lambda(\mathrm{not}_\lambda \ z)w}} \iff \fn{zw}{\mathrm{if}_\lambda(\mathrm{not}_\lambda \ z)w}$$
    \end{framedprop}

    \begin{framedprop}{Operazione $\mathrm{and}_\lambda$}
        Si consideri l'algebra dei booleani di Church; su di essa, è possibile definire l'operazione logica di $and$, come segue: $$\mathrm{and}_\lambda := \fn{z}{\fn{w}{\mathrm{not}_\lambda(\mathrm{if}_\lambda \ z (\mathrm{not}_\lambda \ w))}}$$
    \end{framedprop}

    \subsection{Lambda calcolo}

    \begin{frameddefn}{Lambda calcolo}
        Il \tbf{lambda calcolo} è un sistema formale atto ad analizzare le funzioni e le loro applicazioni. La grammatica del lambda calcolo è la seguente
        \begin{center}
            \begin{tabular}{rcl}
                $M, N$ & $::=$ & $x \smid \lambda x . M \smid MN$ \\
            \end{tabular}
        \end{center}

        dove $\lambda x.M$ indica una funzione della forma $\fn{x}{M}$, e prende il nome di \tbf{lambda astrazione}. Le espressioni del lambda calcolo sono dette \tbf{lambda espressioni}.
    \end{frameddefn}

    \begin{example}[Lambda espressioni]
        I seguenti sono esempi di espressioni del lambda calcolo:

        \begin{itemize}
            \item $(\lambda x.x +1)2$ corrisponde a $(\fn{x}{x+1})2$ ed equivale a 3
            \item $\lambda xy.x(x(xy))$ corrisponde a $\fn{xy}{x(x(xy))}$, ovvero $3_\lambda \in \N_\lambda$
            \item $(\lambda x.xy)(\lambda x.x)$ equivale ad $y$
        \end{itemize}
    \end{example}

    \begin{frameddefn}[label={sub}]{Sostituzione}
        Date due espressioni $M$ ed $N$, ed una variabile $x$, l'operazione di \tbf{sostituzione} rimpiazza ogni occorrenza della variabile $x$ --- all'interno dell'espressione $M$ --- con il termine $N$. In simboli $$M[N/x]$$ 
    \end{frameddefn}

    \begin{example}[Sostituzioni]
        I seguenti sono esempi di sostitutioni all'interno di espressioni:

        \begin{itemize}
            \item $(xy)[\lambda z.z/x]$ corrisponde a $(\lambda z.z)y$, ovvero $y$
            \item $(\fn{x}{y})[x/y]$ corrisponde a $\fn{x}{x}$
        \end{itemize}
    \end{example}

    \begin{framedobs}{Cattura di variabili}
        Si noti che l'operazione di sostituzione, definita nella \cref{sub}, potrebbe cambiare il binding delle variabili definite; tale fenomeno prende il nome di \tbf{cattura di variabili}.
    \end{framedobs}

    \begin{example}[Catture di variabili]
        Si consideri la seguente espressione: $$(\lambda y.M)[N/x]$$ se $N$ contenesse la variabile $y$ in modo libero, si avrebbe che $$\lambda y.(M[N/x])$$ non sarebbe equivalente all'espressione di partenza, poiché $y$ diverrebbe legata. Dunque, la loro equivalenza è garantita solamente se $y \notin \mathrm{free}(N)$.
    \end{example}

    \begin{frameddefn}{Alfa conversione}
        Data una lambda astrazione $\lambda x.M$, si definisce \tbf{alfa conversione} la regola secondo la quale ogni occorrenza di $x$ nella lambda astrazione viene rimpiazzata con un altra variabile. In simboli $$\lambda x.M \alphaconv \lambda y.(M[y/x])$$
    \end{frameddefn}

    \begin{example}[Alfa conversioni]
        Si consideri la seguente lambda astrazione $$\lambda x.x(\lambda z.zw)$$ allora, ad esempio, è vero che $$\lambda x.x(\lambda z.zw) \alphaconv \lambda z.z(\lambda z.zw)$$ avendo rimpiazzato $x$ con $z$.
    \end{example}

    \begin{frameddefn}[label={alpha equiv}]{Alfa equivalenza}
        Due lambda astrazioni $\lambda x.M$ e $\lambda y.N$ sono dette \tbf{alfa equivalenti}, indicato con il simbolo $\equiv_\alpha$ se è vera la seguente: $$\lambda x.M \equiv_\alpha \lambda .N \iff \soe{l}{\lambda x.M \alphaconv \lambda y.N \\ \lambda y.N \alphaconv \lambda x.M}$$
    \end{frameddefn}

    \begin{example}[Alfa equivalenze]
        Si considerino le due seguenti lambda astrazioni $$\centeredsoe{\lambda x.xy \\ \lambda z.zy}$$ e si noti che $$\soe{l}{\lambda x.xy \alphaconv \lambda z.zy \\ \lambda z.zy \alphaconv \lambda x.xy} \iff \lambda x.xy \equiv_\alpha \lambda z.zy$$ dunque le due lambda astrazioni sono alfa equivalenti.
    \end{example}

    \begin{nonexample}[Alfa equivalenze]
        Si considerino le due seguenti lambda astrazioni $$\centeredsoe{\lambda x.x (\lambda z.z w) \\ \lambda z.z(\lambda z.zw)}$$ e si noti che $$\soe{l}{\lambda x.x (\lambda z.zw) \alphaconv \lambda z.z(\lambda z.z w) \\ \lambda z.z(\lambda z.zw) \ \not\mathrel{\mkern-5mu\longrightarrow_{\alpha}} \lambda x.x(\lambda z.zw) } \implies \lambda x.x(\lambda z.zw) \not\equiv_\alpha \lambda z.z(\lambda z.zw)$$ dunque le due lambda astrazioni \tit{non} sono alfa equivalenti
    \end{nonexample}

    \begin{frameddefn}[label={beta conv}]{Beta conversione}
        Data una lambda espressione $(\lambda x.M)$, si definisce \tbf{beta conversione} la regola secondo la quale ogni occorrenza di $x$ all'interno di $M$ viene rimpiazzata dal termine $N$. In simboli $$(\lambda x.M)N \betaconv M[N/x]$$
    \end{frameddefn}

    \begin{example}[Beta conversioni]
        Si consideri la seguente lambda espressione $$(\lambda x.xy)(\lambda z.z)$$ applicando la beta conversione, si ottiene $$(\lambda x.xy)(\lambda z.z) \betaconv (\lambda z.z)y \betaconv y$$
    \end{example}

    \begin{framedobs}{Beta conversioni}
        Di fatto, la beta conversione corrisponde ad un passo computazionale.
    \end{framedobs}

    \begin{framedobs}{Semantica delle beta conversioni}
        Si noti che la beta conversione ha significato solamente in un contesto lazy, poiché considerando ad esempio la lambda espressione $$(\lambda x.7) \omega$$ (dove $\omega$ è rappresenta l'espressione $\omega$ della \cref{omega}) essa è beta equivalente alla lambda espressione $(\lambda x.7)[\omega/x] \betaconv 7$ soltanto se l'espressione $\omega$ non viene valutata.
    \end{framedobs}

    \begin{frameddefn}[label={eta conv}]{Eta conversione}
        Si definisce \tbf{eta conversione} la regola secondo la quale una lambda espressione $(\lambda x.Mx)$ può essere rimpiazzata con $M$, solo se $x$ non è libera. In simboli $$x \notin \mathrm{free}(M) \implies \lambda x.Mx \etaconv M$$
    \end{frameddefn}

    \begin{example}[Eta conversioni]
        Si consideri la seguente lambda espressione $$\lambda x.(\lambda y.y)x$$ si noti che $\mathrm{free}(\lambda y.y) = \varnothing \implies x \notin \mathrm{free}(\lambda y.y)$ e dunque è possibile applicare l'eta conversione, ottenendo quindi $$\lambda x .(\lambda y.y) x \etaconv \lambda y.y$$
    \end{example}

    \begin{framedobs}{Cattura nelle eta conversioni}
        Si noti che, all'interno della \cref{eta conv}, la condizione per cui $x$ non sia libera garantisce che la conversione produca espressioni equivalenti; infatti, se $x$ fosse libera in $M$, poiché in $(\lambda x.Mx)$ non lo è, l'eta conversione non avrebbe mantenuto l'equivalenza delle espressioni considerate.
    \end{framedobs}

    \subsection{Ricorsione}

    \begin{frameddefn}{Punto fisso}
        Data una funzione $f: X \to X$, un elemento $x \in X$ è detto \tbf{punto fisso di $f$} se e solo se $f(x) = x$.
    \end{frameddefn}

    \begin{example}[Punti fissi]
        Sia $f(x) = x^2 -3x +4$; allora, poiché $f(2) = 2^2 - 3 \cdot 2 + 4 = 4 - 6 + 4 = 2$, 2 è un punto fisso di $f$.
    \end{example}

    \begin{example}[Funzioni come punti fissi]
        \label{fn fixed points}
        Si consideri la funzione $$F(g) := h(x) = \soe{ll}{1 & x = 0 \\ x \cdot g(x - 1) & x > 0}$$ che prende in input una funzione; per vedere come opera, calcolando ad esempio $F(\mathrm{succ})$, si ottiene la funzione $$F(\mathrm{succ}) := h(x) = \soe{ll}{1 & x = 0 \\ x \cdot \mathrm{succ}(x - 1) = x \cdot x = x^2 & x > 0}$$ che restituisce 1 se $x$ è 0, altrimenti restituisce $x^2$.

        Allora, il punto fisso di $F$ è la funzione seguente $$\mathrm{fact}(x) = \soe{ll}{1 & x = 0 \\ x \cdot \mathrm{fact}(x - 1) & x > 0}$$ che computa il fattoriale di un numero; infatti, si ha che $$F(\mathrm{fact}) := h(x) = \soe{ll}{1 & x = 0 \\ x \cdot \mathrm{fact}(x - 1) & x > 0} \equiv : \mathrm{fact}$$
    \end{example}

    \begin{frameddefn}{Combinatore di Kleene}
        Si definisce \tbf{combinatore di Kleene}, o \tbf{operatore di punto fisso}, la seguente espressione esprimibile attraverso la grammatica $Fun$ della \cref{fun}: $$\mathrm Y := \fn{f}{((\fn{x}{f(xx)})(\fn{x}{f(xx)}))}$$
    \end{frameddefn}

    \begin{framedprop}{Punto fisso di una funzione}
        Data una funzione, il combinatore di Kleene ne restituisce il punto fisso.
    \end{framedprop}

    \begin{proof}
        Se il combinatore di Kleene è in grado di restituire il punto fisso di una funzione, allora data una funzione $h$, si ha che $\mathrm Yh$ è il suo punto fisso, e dunque per definizione $$h(\mathrm Yh) \equiv \mathrm Yh$$ Allora, svolgendo i calcoli, si ottiene che \centeredeq{0.9}{$\mathrm Yh \betaconv (\fn{x}{h(xx)})(\fn{x}{h(xx)}) \betaconv  h((\fn{x}{h(xx)})(\fn{x}{h(xx)})) \longrightarrow h (\mathrm Y h)$}
    \end{proof}

    \begin{framedobs}[breakable]{Ricorsione attraverso $\mathrm Y$}
        Si noti che, poiché per una funzione $h$ è vero che $h(\mathrm Yh) = \mathrm Y h$, si ha che $$\centeredsoe{h(\mathrm Y h) = \mathrm Y h \\ h (h(\mathrm Y h)) = \mathrm Y h \\ \vdots \\ h( \ldots (h(\mathrm Yh))) = \mathrm Y h}$$ Questo permette di implementare la ricorsione all'interno del paradigma funzionale, come segue: si consideri la funzione $F(g)$ definita all'interno del \cref{fn fixed points}; è possibile definire dunque una funzione simile ad essa, ovvero $$h := \fn{rn}{\soe{ll}{1 & n = 0 \\ n \cdot (r \ (n - 1)) & n > 0}}$$ il cui punto fisso è ancora la funzione che computa il fattoriale di $n$. Inoltre, si noti che: $$
            \centeredsoe{
                (\mathrm Y h) \ k = \\
                = h \ (\mathrm Y h) \ k = \\
                = \rbk{\fn{rn}{\soe{ll}{1 & n = 0 \\ n \cdot (r \ (n - 1)) & n > 0}}} \ (\mathrm Y h) \ k = \\
                = \rbk{\fn{n}{\soe{ll}{1 & n = 0 \\ n \cdot ((\mathrm Y h) \ (n - 1)) & n > 0}}} \ k = \\
                = \soe{ll}{1 & k = 0 \\ k \cdot ((\mathrm Y h) \ (k - 1)) & k > 0}
            }
        $$ dunque, segue che $$
            \centeredsoe{
                (\mathrm Y h) \ 3 = \\
                = 3 \cdot ((\mathrm Y h) \ 2) = \\
                = 3 \cdot 2 \cdot ((\mathrm Y h) \ 1) = \\
                = 3 \cdot 2 \cdot 1 \cdot (1) = \mathrm{fact}(3) \\
            }
        $$
    \end{framedobs}

    \section{$Fun_\rho$: un linguaggio funzionale ricorsivo}

    \subsection{Operatori di ricorsione}

    \begin{framedlem}[label={weak term ric}]{Ricorsione tramite numeri naturali}
        Dato un insieme $A$, un suo elemento $a \in A$, ed una funzione $\func{h}{A}{A}$, si ha che $$\exists ! f: \N \to A \mid \soe{l}{f(0) = a \\ f(\mathrm{succ}(n))= h(f(n))}$$ Dunque $f$ risulta essere l'unico omomorfismo tra le algebre $(\N, \mathrm{zero}, \mathrm{succ})$ e $(A, \mathrm{zero}_A, h)$, per qualche funzione nullaria $\funcmap{\mathrm{zero}_A}{\1}{A}{x}{a}$.
    \end{framedlem}

    \begin{proof}
        Poiché le algebre $(\N, \mathrm{zero}, \mathrm{succ})$ e $(A, \mathrm{zero}_A, h)$ hanno la stessa segnatura, e l'algebra dei numeri naturali è induttiva --- come mostrato nell'\cref{N inductive} --- per la \cref{alg same sign} esiste unico un omomorfismo $\func{f}{\N}{A}$, dunque per definizione stessa di omomorfismo, si verifica che $$f:\N \to A :\soe{l}{f(0) = f(\mathrm{zero}(x)) = \mathrm{zero}_A(f(x)) = a \\ f(\mathrm{succ}(n)) = h(f(n))}$$ poichè $\forall x \in \1 \quad \mathrm{zero}(x) = 0$ ed inoltre $\forall x \in \1 \quad \mathrm{zero}_A(x) = a$.
    \end{proof}

    \begin{frameddefn}{Operatore $\rho$}
        Si definisce \tbf{operatore $\rho$} l'operatore che, attraverso la sintassi $$\rhofun{\ttt{expression}_1}{\ttt{expression}_2}$$ restituisce l'omomorfismo descritto all'interno del \cref{weak term ric}, dove $\ttt{expression}_1$ rappresenta $a$ --- ovvero lo zero dell'algebra $(A, h, \mathrm{zero}_A)$ --- ed $\ttt{expression}_2$ costituisce il costruttore $h: A \to A$.
    \end{frameddefn}

    \begin{framedobs}[label={rho obs}]{Operatore $\rho$}
        Si noti che, per definizione dell'operatore $\rho$, si verifica che $$\rho : \soe{l}{(\rhofun{a}{h}) \ 0 = a \\ (\rhofun{a}{h}) \ (\succfn \ n) = h \ ((\rhofun{a}{h}) \ n)}$$ espresso attravreso i termini delle funzioni definite all'interno del \cref{weak term ric}.
    \end{framedobs}

    \begin{example}[Operatore $\rho$]
        \label{rho ex}
        Si considerino le algebre dei numeri naturali $(\N, \mathrm{zero}, \mathrm{succ})$, e dei booleani di Church $(\mathbb{B}_\lambda, \mathrm{True}_\lambda, \mathrm{not}_\lambda)$, dove $$\funcmap{\mathrm{True}_\lambda}{\1}{\mathbb{B}_\lambda}{x}{\mathrm{true}_\lambda}$$ Allora, si ha che $(\rhofun{\mathrm{true}_\lambda}{\mathrm{not}_\lambda})$ è una funzione tale che $$\soe{l}{(\rhofun{\mathrm{true}_\lambda}{\mathrm{not}_\lambda}) 0 = \mathrm{true}_\lambda \\ (\rhofun{\mathrm{true}_\lambda}{\mathrm{not}_\lambda})(\mathrm{succ} \ n) = \mathrm{not}_\lambda((\rhofun{\mathrm{true}_\lambda}{\mathrm{not}_\lambda})n)}$$ e, considerando la seguente funzione, scritta in forma ricorsiva $$\func{\mathrm{isEven}}{\N}{\mathbb{B}_\lambda}: \soe{l}{\mathrm{isEven}(0) = \mathrm{true}_\lambda \\ \mathrm{isEven}(\mathrm{succ}(n)) = \mathrm{not}_\lambda(\mathrm{isEven}(n))}$$ che è in grado di restituire la parità di un numero naturale, è facilmente verificabile che $$\centeredsoe{(\rhofun{\mathrm{true}_\lambda}{\mathrm{not}_\lambda}) \equiv \mathrm{isEven} \\ (\rhofun{\mathrm{false}_\lambda}{\mathrm{not}_\lambda}) \equiv \mathrm{isFalse}}$$
    \end{example}

    \begin{framedobs}[label={rhofun church}]{Operatore $\rho$ e $\N_\lambda$}
        Si consideri un'algebra $(A, \mathrm{zero}_A, h)$ tale che $a$ sia il suo zero; per l'\cref{rho obs}, dunque, si verifica che $$\centeredsoe{\rhofun{a}{h} \ (\underbrace{\succfn \ ( \ \ldots \ (\succfn}_{n \ \mathrm{volte}} \ 0))) = \\ = h \ (\rhofun{a}{h} \ (\underbrace{\succfn \ ( \ \ldots \ (\succfn}_{n - 1 \ \mathrm{volte}} \ 0)))) = \ldots \\ \ldots = \underbrace{h \ (\ \ldots \ (h}_{n - 1 \ \mathrm{volte}} \ (\rhofun{a}{h} \ (\succfn \ 0)))) = \\ = \underbrace{h \ (\ \ldots \ (h }_{n \ \mathrm{volte}} \ (\rhofun{a}{h} \ 0)))  = \underbrace{h \ (\ \ldots \ (h}_{n \ \mathrm{volte}} \ a) = n_\lambda \ h \ a }$$ dunque vi è una stretta corrispondenza tra l'operatore $\rho$ ed i numeri di Church.
    \end{framedobs}

    \begin{example}[$\N_\lambda$ con $\rho$]
        Per l'\cref{rhofun church}, ad esempio, si ha che $$\centeredsoe{\rhofun{a}{h} \ (\succfn \ (\succfn \ (\succfn \ 0))) = h \ (\rhofun{a}{h} \ (\succfn \ (\succfn \ 0))) = \\ = h \ (h \ (\rhofun{a}{h} \ (\succfn \ 0))) = h \ (h \ (h \ \rhofun{a}{h} \ 0)) = h \ (h \ (h \ a)) \equiv 3_\lambda \ h \ a}$$ 
    \end{example}

    \begin{framedlem}[label={func ric prim}]{Funzione ricorsiva primitiva}
        Dato un insieme $A$, un suo elemento $a \in A$, ed una funzione $\func{h}{A \times \N}{A}$, si ha che $$\exists ! \func{f}{\N}{A} \mid \soe{l}{f(0) = a \\ f(\mathrm{succ}(n)) = h(f(n), n)}$$ Dunque $f$ risulta essere l'unico omomorfismo tra le algebre $(\N, \mathrm{zero}, \mathrm{succ})$ e $(A, \mathrm{zero}_A,h )$, per qualche funzione nullaria $\funcmap{\mathrm{zero}_A}{\1}{A}{x}{a}$.
    \end{framedlem}

    \begin{proof}
        Omessa.
    \end{proof}

    \begin{frameddefn}{Operatore $rec$}
        Si definisce \tbf{operatore $rec$} l'operatore che, attraverso la sintassi $$\recfun{\ttt{expression}_1}{\ttt{expression}_2}$$ restituisce l'omomorfismo descritto all'interno del \cref{weak term ric}, dove $\ttt{expression}_1$ rappresenta $a$ --- ovvero lo zero dell'algebra $(A,\mathrm{zero}_A, h)$ --- ed $\ttt{expression}_2$ costituisce il costruttore $h: A \times \N \to A$.
    \end{frameddefn}

    \begin{framedobs}[label={rec obs}]{Operatore $rec$}
        Si noti che, per definizione dell'operatore $rec$, si verifica che $$rec: \soe{l}{(\recfun{a}{h}) \ 0 = a \\ (\recfun{a}{h}) \ (\succfn \ n) = h \ ((\recfun{a}{h}) \ n) \ n}$$ espresso attraverso i termini delle funzioni definite all'interno del \cref{func ric prim}.
    \end{framedobs}

    \begin{framedprop}{Equivalenza tra $\rho$ e $rec$}
        Si consideri la grammatica $Fun$ della \cref{fun}; allora, date due sue espressioni $M$ ed $N$, si ha che $$\rhofun{M}{N} \equiv \recfun{M}{(\fn{xy}{Nx})}$$
    \end{framedprop}

    \proofind{
        La dimostrazione procede per induzione su $n$.
    }{
        Per $n = 0$, si ha che $$\rhofun{M}{N} \ 0 = M = \recfun{M}{(\fn{xy}{Nx})}$$ per l'\cref{rho obs} e l'\cref{rec obs}.
    }{
        Dato $n > 0$, si ha che $$\rhofun{M}{N} \ n = \recfun{M}{(\fn{xy}{Nx})} \ n$$
    }{
        Per $n + 1 = \succfn(n)$, si ha che $$\centeredsoe{\recfun{M}{(\fn{xy}{Nx})} \ (\succfn \ n) = (\fn{xy}{Nx}) \ (\recfun{M}{\fn{xy}{Nx}} \ n) \ n = \\ = (\fn{xy}{Nx}) \ (\rhofun{M}{N} \ n) \ n \longrightarrow N \ (\rhofun{M}{N} \ n)}$$ per ipotesi induttiva.
    }

    \begin{example}[Equivalenze tra $\rho$ e $rec$]
        È possibile esprimere la funzione $\mathrm{isEven}$ definita nell'\cref{rho ex}, attraverso l'operatore $rec$, come segue: $$\mathrm{isEven} \equiv (\rhofun{\mathrm{true}_\lambda}{\mathrm{not}_\lambda}) \equiv (\recfun{\mathrm{true}_\lambda}{(\fn{xn}{\mathrm{not}_\lambda \ x})})$$
    \end{example}

    \begin{frameddefn}[label={fun rho}]{Grammatica $Fun_\rho$}
        Si consideri la grammatica $Fun$ definita all'interno della \cref{fun}; la seguente è una sua estensione, che prenderà il nome di $Fun_\rho$, che include al suo interno una clausola con l'operatore $rec$:

        \begin{center}
            \begin{tabular}{rcl}
                $M, N$ & $::=$ & $x \smid \fn{x}{M} \smid MN \smid 0 \smid \mathrm{succ} \ M \smid \recfun{M}{N}$ \\
            \end{tabular}
        \end{center}

        dove si noti che 0 non sta ad indicare tutte le costanti, ma esclusivamente lo 0, in quanto non è necessario includere le altre poiché la grammatica è fornita della funzione $\mathrm{succ}$.
    \end{frameddefn}

    \begin{example}[Operatore $rec$ in $Fun_\rho$]
        \label{plus def}
        Sia $\funcmap{\mathrm{plus}}{\N \times \N}{\N}{(x,y)}{x + y}$ la funzione che somma $x$ ad $y$, definita ricorsivamente --- attraverso le espressioni della grammatica $Fun_\rho$ definita nella \cref{fun rho} --- come segue: $$\mathrm{plus} : \soe{l}{\mathrm{plus} \ 0 \ y = y \\ \mathrm{plus} \ (\succfn \ n) \ y = \succfn \ (\mathrm{plus} \ n \ y)}$$ si noti dunque che è possibile esprimerla attraverso l'operatore $rec$ come segue: $$\mathrm{plus} \equiv (\fn{xy}{\recfun{y}{(\fn{wz}{\succfn \ w})} \ x})$$ poiché $$\mathrm{plus} \ 0 \ y = \recfun{y}{(\fn{wz}{\succfn \ w)}} \ 0 = y$$ (si noti l'\cref{rec obs}), ed inoltre $$\centeredsoe{\mathrm{plus} \ (\succfn \ n) \ y = \recfun{y}{(\fn{wz}{\succfn \ w}) \ (\succfn \ n)} = \\ = (\fn{wz}{\succfn \ w}) \ (\recfun{y}{(\fn{wz}{\succfn \ w})} \ n ) \ n = \\ = (\fn{wz}{\succfn \ w}) \ (\mathrm{plus} \ n \ y ) \ n  \longrightarrow \succfn \ (\mathrm{plus} \ n \ y)}$$
    \end{example}

    \begin{example}[Operatore $rec$ in $Fun_\rho$]
        Sia $\funcmap{\mathrm{twice}}{\N}{\N}{n}{2 \cdot n}$ la funzione che raddoppia l'input fornito, definita ricorsivamente --- attraverso le espressioni della grammatica $Fun_\rho$ definita nella \cref{fun rho} --- come segue: $$\mathrm{twice} : \soe{l}{\mathrm{twice} \ 0 = 0 \\ \mathrm{twice} \ (\succfn \ n) = \succfn \ (\succfn \ (\mathrm{twice} \ n))}$$ si noti dunque che è possibile esprimerla attraverso l'operatore $rec$ come segue: $$\mathrm{twice} \equiv \recfun{0}{(\fn{xy}{\succfn \ (\succfn \ x))}}$$ poiché $$\mathrm{twice} \ 0 = \recfun{0}{(\fn{xy}{\succfn \ (\succfn \ x))}}\ 0 = 0$$ (si noti l'\cref{rec obs}), ed inoltre $$\centeredsoe{\mathrm{twice} \ (\succfn \ n) = \recfun{0}{(\fn{xy}{\succfn \ (\succfn \ x))}}\ (\succfn \ n) = \\ = (\fn{xy}{\succfn \ (\succfn \ x))} \ (\recfun{0}{(\fn{xy}{\succfn \ (\succfn \ x))}} \ n) \ n =  \\ = (\fn{xy}{\succfn \ (\succfn \ x))} \ (\mathrm{twice} \ n) \ n \longrightarrow \\ \longrightarrow (\fn{y}{\succfn \ (\succfn \ (\mathrm{twice} \ n))}) \ n \longrightarrow \succfn \ (\succfn \ (\mathrm{twice} \ n))}$$
    \end{example}

    \chapter{Paradigma imperativo}

    \section{Programmi}
    
    \subsection{Memoria}

    \begin{frameddefn}[label={store}]{Memoria}
        Sia $G$ una grammatica; per simulare la \tbf{memoria}, all'interno del paradigma imperativo verranno utilizzati ambienti definiti come segue: $$\mathrm{Env} := \{f \mid f : \mathrm{Var} \xrightarrow{fin} \mathrm{Loc} \}$$ dove $\mathrm{Loc}$ è un insieme di locazioni di memoria; inoltre, si definisce il seguente insieme $$\mathrm{Store} := \{f \mid f : \mathrm{Loc} \xrightarrow{fin} \mathrm{Val} \}$$ dunque, le funzioni $E \in \mathrm{Env}$ associano le variabili ad una locazione in memoria, mentre le funzioni $S \in \mathrm{Store}$ associano le locazioni ai valori, simulando di fatto i \tit{puntatori}, i quali caratterizzano i linguaggi imperativi.
    \end{frameddefn}

    \begin{frameddefn}{Programma}
        Nel paradigma imperativo, un \tbf{programma} è un componente semantico che non restituisce valori --- dunque non ha \tit{side effect} --- ma cambia lo stato memoria.
    \end{frameddefn}

    \subsection{Clausole imperative}

    \begin{frameddefn}{Clausola $skip$}
        La clausola $skip$ verrà utilizata attraverso la sintassi $$skip$$ ed equivale a non effettuare alcuna operazione.
    \end{frameddefn}
    
    \begin{frameddefn}{Clausola $seq$}
        La clausola $seq$ verrà utilizzata attraverso la sintassi $$\ttt{program}_1;\ttt{program}_2$$ che sta ad indicare che verrà prima eseguito $\ttt{program}_1$, e successivamente $\ttt{program}_2$.
    \end{frameddefn}

    \begin{frameddefn}{Clausola $ite$}
        La clausola $ite$ verrà utilizzata attraverso la sintassi $$\ite{\ttt{expression}}{\ttt{program}_1}{\ttt{program}_2}$$ dove se $M$ è un espressione che può essere valutata a $true$, verrà eseguito $\ttt{program}_1$, altrimenti verrà eseguito $\ttt{program}_2$.
    \end{frameddefn}

    \begin{frameddefn}{Clausola $while$}
        La clasuola $while$ verrà utilizzata attraverso la sintassi $$\while{\ttt{expression}}{\ttt{program}}$$ dove --- se \ttt{expression} è un espressione che può essere valutata a $true$ o $false$ --- viene eseguito $\ttt{program}$ fintanto che \ttt{expression} viene valutata a $true$.
    \end{frameddefn}

    \begin{frameddefn}{Clausola $var$}
        TODO
    \end{frameddefn}

    \begin{frameddefn}{Clausola $assign$}
        La clausola $assign$ verrà utilizzata attraverso la sintassi $$\ttt{variable}  := \ttt{expression}$$ attraverso la quale a \ttt{variable} verrà assegnato il valore di \ttt{expression}.
    \end{frameddefn}

    \section{$Imp$: un linguaggio imperativo}

    \subsection{Definizioni}

    \begin{frameddefn}[label={imp}]{Grammatica $Imp$}
        Si consideri la grammatica $Exp$ definita all'interno della \cref{exp} (si noti che non si tratta di $Exp$ estesa); è possibile estenderla come segue:

        \begin{center}
            \begin{tabular}{rcl}
                $M, N$ & $::=$ & $k \smid true \smid false \smid x \smid M + N \smid M * N \smid M < N$ \\
            \end{tabular}
        \end{center}

        dove $true$ e $false$ sono valori booleani di verità. Allora, sia $Imp$ la grammatica composta da tale estensione di $Exp$, e dalla seguente:

        \begin{center}
            \begin{tabular}{rcl}
                $p, q$ & $::=$ & $skip \smid p;q \smid \ite{M}{p}{q} \smid \while{M}{p}$ \\
                       & & $\varin{x}{M}{p} \smid x:=M$ \\
            \end{tabular}
        \end{center}

        L'insieme degli ambienti di $Imp$ è strutturato come nella \cref{store}. Inoltre, per effettuare le valutazioni, vengono definite le seguenti semantiche operazionali: $$\centeredsoe{\stackrel{M}{\leadsto}\ \subseteq \mathrm{Env} \times Exp \times \mathrm{Store} \times \mathrm{Val} \\ \stackrel{p}{\leadsto} \ \subseteq \mathrm{Env} \times Imp \times \mathrm{Store} \times \mathrm{Store}}$$ ed i loro giudizi operazionali verranno indicati come segue: $$\centeredsoe{\opjudstore[M]{E}{M}{S}{v} \\ \opjudstore[p]{E}{p}{S}{S'}}$$
    \end{frameddefn}

    \begin{frameddefn}{Concatenazione di store}
        Siano $S_1$ ed $S_2$ due store di una grammatica imperativa; allora, si definisce \tbf{concatenazione} di $S_1$ ed $S_2$ la seguente funzione $$\funcmap{S_1, S_2}{\mathrm{Store} \times \mathrm{Store}}{\mathrm{Store}}{x}{\soe{ll}{S_2(x) & x \in \dom(S_2) \lor x \in \dom(S_1) \cap \dom(S_2) \\ S_1(x) & x \in \dom(S_1)}}$$ dunque, nella concatenazione $S_2$ sovrascrive le tuple che sono presenti anche in $S_1$.
    \end{frameddefn}

    \begin{framedobs}{Semantiche di $Imp$}
        Sia $Imp$ la grammatica della \cref{imp}, e si considerino le sue semantiche operazionali; esse sono definite tali che la semantica $\stackrel{M}{\leadsto}$ delle espressioni sia in grado di restituire valori, ma non di cambiare la memoria, mentre la semantica $\stackrel{p}{\leadsto}$ dei programmi non restituisca valori, ma alteri lo stato della memoria. 
    \end{framedobs}

    \subsection{Semantica operazionale di $Imp$}

    \begin{framedprop}[label={imp sem},breakable]{Semantica operazionale di $Imp$}
        Sia $Imp$ la grammatica definita all'interno della \cref{imp}, e siano $E \in \mathrm{Env}$ e $S \in \mathrm{Store}$; allora, si definiscono le seguenti regole operazionali (si noti che, per brevità, verrà utilizzato il simbolo $\leadsto$ all'interno dei giudizi di entrambe le semantiche di $Imp$):

        \begin{itemize}
            \item \tbf{costanti}: $$[const] \ \opjudstore{E}{k}{S}{k}$$
            \item \tbf{variabili}: $$\exists v \in \mathrm{Val} \mid S(E(x)) = v \implies [vars] \ \opjudstore{E}{x}{S}{v}$$
            \item \tbf{somme}: $$\exists v_1, v_2 \in \mathrm{Val} \mid v = v_1 + v_2 \implies [plus] \ \dfrac{\opjudstore{E}{M}{S}{v_1} \quad \opjudstore{E}{N}{S}{v_2}}{\opjudstore{E}{M + N}{S}{v}}$$
            \item \tbf{prodotti}: $$\exists v_1, v_2 \in \mathrm{Val} \mid v = v_1 \cdot v_2 \implies [times] \ \dfrac{\opjudstore{E}{M}{S}{v_1} \quad \opjudstore{E}{N}{S}{v_2}}{\opjudstore{E}{M * N}{S}{v}}$$
            \item \tbf{minorazioni}: $$v_1 < v_2 \implies [lt_1] \ \dfrac{\opjudstore{E}{M}{S}{v_1} \quad \opjudstore{E}{N}{S}{v_2}}{\opjudstore{E}{M  < N}{S}{true}}$$ $$v_1 \ge v_2 \implies [lt_2] \ \dfrac{\opjudstore{E}{M}{S}{v_1} \quad \opjudstore{E}{N}{S}{v_2}}{\opjudstore{E}{M  <  N}{S}{false}}$$
            \item \tbf{skip}: $$[skip] \ \opjudstore{E}{skip}{S}{S}$$
            \item \tbf{composizioni sequenziali}: $$[seq] \ \dfrac{\opjudstore{E}{p}{ S}{S'} \quad \opjudstore{E}{q}{ S'}{S''}}{\opjudstore{E}{p;q}{S}{S''}}$$
            \item \tbf{if-then-else}: $$[ite_1] \ \dfrac{\opjudstore{E}{M}{ S}{true} \quad \opjudstore{E}{p}{S}{S'}}{\opjudstore{E}{\ite{M}{p}{q}}{S}{S'}}$$ $$[ite_2] \ \dfrac{\opjudstore{E}{M}{S}{false} \quad \opjudstore{E}{q}{S}{S''}}{\opjudstore{E}{\ite{M}{p}{q}}{S}{S''}}$$
            \item \tbf{while}: $$[while_1] \ \dfrac{\opjudstore{E}{M}{S}{true} \quad \opjudstore{E}{p}{S}{S'} \quad \opjudstore{E}{\while{M}{p}}{ S'}{S''}}{\opjudstore{E}{\while{M}{p}}{ S}{S''}}$$ $$[while_2] \ \dfrac{\opjudstore{E}{M}{S}{false}}{\opjudstore{E}{\while{M}{p}}{S}{S}}$$
            \item \tbf{dichiarazioni}: $$\exists l \in \mathrm{Loc} \mid l \notin \dom(S) \implies$$ $$\implies [var] \ \dfrac{\opjudstore{E}{M}{S}{v} \quad \opjudstore{E\{(x,l)\}}{p}{S\{(l,v)\}}{S'}}{\opjudstore{E}{\varin{x}{M}{p}}{S}{S'}}$$
            \item \tbf{assegnazioni}: $$\exists l \in \mathrm{Loc} \mid E(x) = l \implies [assign] \ \dfrac{\opjudstore{E}{M}{S}{v}}{\opjudstore{E}{x := M}{ S}{S\{(l, v)\}}}$$
        \end{itemize}
    \end{framedprop}

    \section{Memoria contigua}

    \subsection{Definizioni}

    \begin{frameddefn}{Memoria contigua}
        Al fine di implementare gli \tit{array} all'interno del paradigma imperativo, è necessario definire la \tbf{memoria contigua}, dunque si definisce il seguente insieme di locazioni $$\displaystyle \mathrm{Loc}^+ := \bigcup_{n \in \N}{\mathrm{Loc}^n}$$ poiché è in grado di supportare infinite sequenze di elementi, e si assume che queste siano contigue in memoria.
    \end{frameddefn}

    \begin{frameddefn}{Clausola $arr$}
        La clausola $arr$ verrà utilizzata attraverso la sintassi $$\arrin{\ttt{variable}}{[\ttt{expression}_1, \ldots, \ttt{expression}_n]}{\ttt{program}}$$ la quale pone $\ttt{variable}$ pari all'array $[\ttt{expression}_1, \ldots, \ttt{expression}_n]$, all'interno di $\ttt{program}$.
    \end{frameddefn}

    \begin{frameddefn}{Clausola $loc$}
        La clausola $loc$ verrà utilizzata attraverso la sintassi $$\ttt{variable}[\ttt{expression}]$$ attraverso la quale --- assumendo che \ttt{variable} sia un array --- verrà effettuato l'accesso all'\ttt{expression}-esima posizione di \ttt{variable}.
    \end{frameddefn}

    \begin{frameddefn}{Clausola $proc$}
        La clausola $proc$ verrà utilizzata attraverso la sintassi $$\procin{\ttt{variable}_1}{\ttt{variable}_2}{\ttt{program}_1}{\ttt{program}_2}$$ la quale definisce la \tit{procedura} $\ttt{variable}_1(\ttt{variable}_2)$, il cui corpo è costituito da $\ttt{program}_1$, ed è possibile utilizzarla all'interno di $\ttt{program}_2$.
    \end{frameddefn}

    \begin{frameddefn}{Clausola $call$}
        La clausola $call$ verrà utilizzata attraverso la sintassi $$\call{\ttt{variable}}{\ttt{expression}}$$ la quale effettua una chiamata alla procedura $\ttt{variable}$, fornendole come parametro $\ttt{expression}$.
    \end{frameddefn}

    \section{$All$: un linguaggio imperativo completo}

    \subsection{Definizioni}

    \begin{frameddefn}[label={all}]{Grammatica $All$}
        Sia $All$ la grammatica, estensione di $Imp$ definita nella \cref{imp}, composta dalle seguenti grammatiche:

        \begin{center}
            \begin{tabular}{rcl}
                $k$ & $::=$ & $0 \smid 1 \smid \ldots \smid true \smid false$ \\
                $V$ & $::=$ & $x \smid x[M]$ \\
                $M, N$ & $::=$ & $k \smid V \smid M + N \smid M * N \smid M   <  N$ \\
                $p,q$ & $::=$ & $skip \smid p;q \smid \ite{M}{p}{q}$ \\
                      & & $\while{M}{p} \smid \varin{x}{M}{p} \smid \arrin{x}{[M_0, \ldots, M_n]}{p}$ \\
                      & & $V := M \smid \procin{y}{x}{p}{q} \smid \call{y}{M}$ \\
            \end{tabular}
        \end{center}

        Dunque, essa è composta da:

        \begin{itemize}
            \item una grammatica per le \tit{costanti};
            \item una grammatica per le \tit{espressioni assegnabili}, che prende il nome di $LExp$ (\tit{left expressions}); per valutare le sue espressioni, si introduce la seguente semantica: $$\stackrel{V}{\leadsto} \ \subseteq \mathrm{Env} \times LExp \times \mathrm{Store} \times \mathrm{Loc}$$
            \item una grammatica per le \tit{espressioni valutabili}, la quale consiste in un'estensione di $Exp$ definita nella \cref{exp};
            \item una grammatica per i \tit{programmi}, la quale consiste in un'estensione di $Imp$ definita nella \cref{imp}.
        \end{itemize}

        Si noti che, poiché tale grammatica supporta gli array, è necessario fornire ad $All$ locazioni di memoria contigue. Inoltre, l'insieme degli ambienti di $All$ è definito come segue: $$\mathrm{Env} := \{f \mid f : \mathrm{Var} \xrightarrow{fin} \mathrm{Loc}^+ \cup (\mathrm{Var} \times All \times \mathrm{Env})\}$$
    \end{frameddefn}

    \subsection{Semantica operazionale di $All$}

    \begin{framedprop}[label={all sem}, breakable]{Semantica operazionale di $All$}
        Sia $All$ la grammatica definita all'interno della \cref{all}, e siano $E \in \mathrm{Env}$ e $S \in \mathrm{Store}$; allora, in aggiunta alle regole $$[const], \ [plus], \ [times], \ [lt_1], \ [lt_2], \ [skip], \ [seq], \ [ite_1], \ [ite_2], \ [while_1], \ [while_2], \ [var]$$ descritte nell'\cref{imp sem}, si definiscono le seguenti:

        \begin{itemize}
            \item \tbf{locazioni}: $$\exists l \in \mathrm{Loc}^+ \mid E(x) = l \implies [loc_1] \ \opjudstore[V]{E}{x}{S}{l}$$
            \item \tbf{locazioni in array}: $$\exists (l_0, \ldots, l_n) \in \mathrm{Loc}^+ \mid E(x) = \abk{l_0, \ldots, l_n} \implies$$ $$\implies \forall m \in [0, n] \quad [loc_2] \ \dfrac{\opjudstore[M]{E}{M}{S}{m}}{\opjudstore[V]{E}{x[M]}{S}{l_m}}$$
            \item \tbf{reference}: $$\exists v \in \mathrm{Val} \mid S(l) = v \implies [ref] \ \dfrac{\opjudstore[V]{E}{V}{S}{l}}{\opjudstore[M]{E}{V}{S}{v}}$$
            \item \tbf{assegnazioni}: $$[assign] \ \dfrac{\opjudstore[M]{E}{M}{S}{v} \quad \opjudstore[V]{E}{V}{S}{l}}{\opjudstore[p]{E}{V := M}{S}{S\{(l,v)\}}}$$
            \item \tbf{array}: $$\exists (l_0, \ldots, l_n) \in \mathrm{Loc}^+ \mid l_0, \ldots, l_n \notin \dom(S) \implies$$ \centeredeq{0.9}{$\implies [arr] \ \dfrac{\opjudstore[M]{E}{M_0}{S}{v_0} \quad \ldots \quad \opjudstore[M]{E}{M_n}{S}{v_n} \quad \opjudstore[p]{E\{(x, (l_0, \ldots, l_n))\}}{p}{S\{(l_0, v_0), \ldots, (l_n, v_n)\}}{S'}}{\opjudstore[p]{E}{\arrin{x}{[M_0, \ldots, M_n]}{p}}{S}{S'}}$}
            \item \tbf{procedure}: $$[proc] \ \dfrac{\opjudstore[p]{E\{(y,(x,p, E))\}}{q}{S}{S'}}{\opjudstore[p]{E}{\procin{y}{x}{p}{q}}{S}{S'}}$$
        \end{itemize}

        Per quanto concerne le regole della clausola $call$, si consultino la \cref{all v}, la \cref{all r} e la \cref{all n}.
    \end{framedprop}

    \begin{framedobs}{Variabili in $All$}
        Si considerino le regole della grammatica $All$, definite nella'\cref{all sem}, e si noti che in essa non è presente la regola di inferenza $[vars]$; infatti, all'interno di $All$, l'unico modo per accedere al valore di una variabile è tramite \tit{reference}, dunque utilizzando $[loc_1]$ assieme a $[ref]$, ed il che è necessario poiché $All$ deve implementare gli array.
    \end{framedobs}

    \begin{frameddefn}{Semantiche di $call$}
        È possibile effettuare le chiamate alle procedure attraverso le seguenti semantiche operazionali:

        \begin{itemize}
            \item \tbf{call-by-value}, la quale corrisponde ad una semantica \tit{eager statica}, e gli argomenti alle procedure sono espressioni non assegnabili, e vengono valutate;
            \item \tbf{call-by-reference}, la quale corrisponde ad una semantica \tit{eager statica}, e gli argomenti alle procedure sono espressioni assegnabili, e vengono valutate;
            \item \tbf{call-by-name}, la quale corrisponde ad una semantica \tit{lazy statica}, e gli argomenti alle procedure sono espressioni assegnabili, ma non vengono valutate.
        \end{itemize}
    \end{frameddefn}

    \begin{framedprop}[label={all v}]{$All_\mathrm{V}$}
        Sia $All$ la grammatica definita nella \cref{all}; per poter valutare le sue espressioni attraverso la semantica \tit{call-by-value}, è necessario definire la seguente regola di inferenza:

        \begin{itemize}
            \item \tbf{call-by-value}: $$\exists l \in \mathrm{Loc} - \dom(S) \land E(y) = (x, p, E') \implies$$ $$\implies [call]_{value} \ \dfrac{\opjudstore[M]{E}{M}{S}{v} \quad \opjudstore[p]{E'\{(x,l)\}}{p}{S\{(l,v)\}}{S'}}{\opjudstore[p]{E}{\call{y}{M}}{S}{S'}}$$
        \end{itemize}
    \end{framedprop}

    \begin{framedprop}[label={all r}]{$All_\mathrm{R}$}
        Sia $All$ la grammatica definita nella \cref{all}; per poter valutare le sue espressioni attraverso la semantica \tit{call-by-reference}, è necessario definire la seguente regola di inferenza: 

        \begin{itemize}
            \item \tbf{call-by-reference}: $$\exists l \in \mathrm{Loc} \mid l \in \dom(S) \land E(y) = (x, p, E') \implies$$ $$\implies [call]_{ref} \ \dfrac{\opjudstore[V]{E}{V}{S}{l} \quad \opjudstore[p]{E'\{(x,l)\}}{p}{S}{S'}}{\opjudstore[p]{E}{\call{y}{V}}{S}{S'}}$$
        \end{itemize}
    \end{framedprop}

    \begin{framedprop}[label={all n}]{$All_\mathrm{N}$}
        Sia $All$ la grammatica definita nella \cref{all}; per poter valutare le sue espressioni attraverso la semantica \tit{call-by-name}, è necessario ridefinire l'insieme degli ambienti, come segue $$\mathrm{Env} := \{f \mid f : \mathrm{Var} \xrightarrow{fin} \mathrm{Loc}^+ \cup (\mathrm{Var} \times All \times \mathrm{Env}) \cup (LExp \times \mathrm{Env})\}$$ ed inoltre vengono aggiunte le due regole di inferenza che seguono:

        \begin{itemize}
            \item \tbf{locazioni}: $$E(x) = (V, E') \implies [loc_3] \ \dfrac{\opjudstore[V]{E'}{V}{S}{l}}{\opjudstore[V]{E}{x}{S}{l}}$$
            \item \tbf{call-by-name}: $$E(y) = (x, p, E') \implies [call]_{name} \ \dfrac{\opjudstore[p]{E'\{(x,(V,E))\}}{p}{S}{S'}}{\opjudstore[p]{E}{\call{y}{V}}{S}{S'}}$$
        \end{itemize}
    \end{framedprop}

    \begin{framedlem}{Semantiche di $All$}
        Sia $All$ la grammatica definita nella \cref{all}; allora, si ha che $$All_\mathrm{V} \not\equiv All_\mathrm{R} \not\equiv All_\mathrm{N}$$
    \end{framedlem}
    
    \begin{proof}
        Si consideri il seguente programma $$\procin{y}{x}{p}{q}$$ e si noti che:
        
        \begin{itemize}
            \item quando viene effettuata la chiamata $\call{y}{M}$ attraverso la semantica call-by-value viene creata una nuova locazione per $x$;
            \item diversamente, quando viene effettuata la chiamata $\call{y}{V}$, attraverso semantiche call-by-reference e call-by-name, non verranno create nuove locazioni per $x$, ma verrà utilizzata direttamente la locazione associata a $V$.
        \end{itemize}

        Di conseguenza, il programma restituisce stati diversi della memoria in base alla semantica utilizzata; questo dimostra che $All_\mathrm{V} \not\equiv All_\mathrm{R}, All_\mathrm{N}$.

        Si consideri ora il seguente programma $$\varin{x}{0}{\arrin{z}{[3, 7]}{\procin{y}{w}{x := 1; \ w := 15}{\call{y}{z[x]}}}}$$ e si noti che:

        \begin{itemize}
            \item valutando tale programma attraverso semantica call-by-reference, durante la chiamata $y(z[x])$ l'espressione $x$ viene valutata immediatamente, e varrà dunque $0$,  di conseguenza $w$ punterà alla locazione $z[x] = z[0]$;
            \item diversamente, valutando tale programma attraverso semantica call-by-name, durante la chiamata $y(z[x])$ l'espressione $z[x]$ non verrà valutata e il calcolo verrà rimandato fino all'espressione $w := 15$, in cui diventa strettamente necessario calcolare $z[x]$; di conseguenza, poiché prima di tale operazione vi è $x := 1$, $w$ punterà alla locazione $z[x] = z[1]$.
        \end{itemize}

        Di conseguenza, il programma restituisce stati diversi della memoria in base alla semantica utilizzata; questo dimostra che $All_\mathrm{R} \not\equiv All_\mathrm{N}$, e dunque segue la tesi.
    \end{proof}

    \chapter{Correttezza dei programmi}
    
    \section{Correttezza nel paradigma imperativo}

    \subsection{Formule imperative}

    \begin{frameddefn}{Tripla di Hoare}
        Si definisce \tbf{tripla di Hoare} la seguente clausola: $$\hoare{A}{p}{B}$$ dove $A$ --- che prende il nome di \tbf{precondizione} --- e $B$ --- che prende il nome di \tbf{postcondizione} --- sono espressioni booleane, e $p$ è un programma. La sua \tit{interpretazione di correttezza parziale} è la seguente: \curlyquotes{stando in uno stato che soddisfa $A$, ed eseguendo $p$ a partire da quest'ultimo, se $p$ termina, allora esso terminerà in uno stato che soddisfa $B$}.
    \end{frameddefn}

    \begin{frameddefn}[label={imp formula}]{Formula imperativa}
        Si definisce \tbf{formula imperativa} un'espressione appartenente alla seguente grammatica: $$\varphi \ ::= \ A \smid \hoare{B}{p}{C}$$ dove $A$, $B$ e $C$ sono espressioni booleane, e $p$ è un programma.
    \end{frameddefn}

    \begin{framedprop}{Inferenza delle formule imperative}
        Si considerino le formule imperative descritte all'interno della \cref{imp formula}; allora, si definiscono le seguenti regole di inferenza:

        \begin{itemize}
            \item \tbf{true}: $$\hoare{A}{p}{true}$$ poiché, per qualsiasi programma $p$, indipendentemente dalla precondizione $A$, la tripla di Hoare verrà soddisfatta;
            \item \tbf{false}: $$\hoare{false}{p}{B}$$ poiché la tripla di Hoare è vera a vuoto, in quando la precondizione non può essere soddisfatta poiché è $false$;
            \item \tbf{strengthening}: $$\dfrac{A \supset B \quad \hoare{B}{p}{C}}{\hoare{A}{p}{C}}$$ poiché se $A$ implica $B$, e si raggiunge uno stato che soddisfa $C$ quando $p$ termina partendo da uno stato che soddisfa $B$, allora sicuramente partendo da uno stato che soddisfa $A$, quando $p$ termina, $C$ sarà soddisfatta dallo stato terminale;
            \item \tbf{weakening}: $$\dfrac{\hoare{C}{p}{B} \quad B \supset A}{\hoare{C}{p}{A}}$$ poiché se $B$ implica $A$, e si raggiunge uno stato che soddisfa $B$ quando $p$ termina partendo da uno stato che soddifa $C$, allora sicuramente partendo da uno stato che soddisfa $C$, quando $p$ termina, $A$ sarà soddisfatta dallo stato terminale; si noti che le regole di \tit{strengthening} e di \tit{weakening} sono l'una il duale dell'altra;
            \item \tbf{and}: $$\dfrac{\hoare{A}{p}{B_0} \quad \hoare{A}{p}{B_1} \quad \ldots \quad \hoare{A}{p}{B_n}}{\hoare{A}{p}{B_0 \land B_1 \land \ldots \land B_n}}$$ poiché, se partendo da uno stato che soddisfa $A$, una volta terminata l'esecuzione, $p$ raggiunge uno stato che soddisfa $B_0$ e $B_1, \ldots, B_n$, allora soddisferà sicuramente anche $B_0 \land B_1 \land \ldots \land B_n$;
            \item \tbf{or}: $$\dfrac{\hoare{B_0}{p}{A} \quad \hoare{B_1}{p}{A} \quad \ldots \quad \hoare{B_n}{p}{A}}{\hoare{B_0 \lor B_1 \lor \ldots \lor B_n}{p}{A}}$$ poiché, se partendo da un qualsiasi stato tra $B_0$ e $B_1, \ldots, B_n$, una volta terminata l'esecuzione, $p$ raggiunge uno stato che soddisfa $A$, allora lo stato iniziale soddisferà anche $B_0 \lor B_1 \lor \ldots \lor B_n$; si noti che le regole \tit{and} ed \tit{or} sono l'una il duale dell'altra;
        \end{itemize}
    \end{framedprop}

    \subsection{Logica di Hoare}

    \begin{frameddefn}[label={hoare logic}]{Logica di Hoare}
        Si definisce \tbf{logica di Hoare} la seguente grammatica:

        \begin{center}
            \begin{tabular}{rcl}
                $M, N$ & $::=$ & $k \smid x \smid M + N \smid M * N$ \\
                $A, B$ & $::=$ & $true \smid false \smid A \supset B \smid M <  N \smid M = N$ \\
                $p, q$ & $::=$ & $skip \smid p;q \smid x:=M \smid \ite{B}{p}{q} \smid \while{B}{p}$ \\
            \end{tabular}
        \end{center}

        dove la prima grammatica comprende le espressioni, la seconda le espressioni booleane, e la terza i programmi.
    \end{frameddefn}

    \begin{framedprop}[breakable]{Regole della logica di Hoare}
        I seguenti sono i \tit{significati assiomatici} (o \tit{regole di inferenza speciali}), della logica di Hoare:

        \begin{itemize}
            \item \tbf{skip}: $$\hoare{A}{skip}{A}$$
            \item \tbf{composizioni sequenziali}: $$\dfrac{\hoare{A}{p}{B} \quad \hoare{B}{q}{C}}{\hoare{A}{p;q}{C}}$$
            \item \tbf{if-then-else}: $$\dfrac{\hoare{A \land C}{p}{B} \quad \hoare{A \land \lnot C}{q}{B}}{\hoare{A}{\ite{C}{p}{q}}{B}}$$
            \item \tbf{while}: $$\dfrac{\hoare{A \land C}{p}{A}}{\hoare{A}{\while{C}{p}}{A \land \lnot C}}$$
            \item \tbf{assegnazioni}: $$\hoare{B[M/x]}{x := M}{B}$$
        \end{itemize}
    \end{framedprop}

    \begin{frameddefn}{Invarianti}
        Sia $A$ un'espressione booleana della logica di Hoare; essa è detta \tbf{invariante} se e solo se, per qualche espressione booleana $B$ e programma $p$, si ha che $$\hoare{A}{\while{B}{p}}{A \land \lnot B}$$ ovvero, la condizione $A$ è verificata \tit{prima e dopo} l'esecuzione di $p$.
    \end{frameddefn}

    \begin{example}[Correttezza di programmi]
        Si consideri il seguente programma --- espresso in termini della logica di Hoare, definita nella \cref{hoare logic} --- in grado di calcolare quoziente e resto dati dal rapporto di due numeri in input (nel programma, $x$ ed $y$): $$b :=x; \ a := 0; \ \while{b \ge y}{(b := b - y ; \ a := a + 1)}$$ È possibile dimostrarne la correttezza attraverso il seguente albero di valutazione:

        $$(*) \ \dfrac{x \ge 0 \supset (x = 0 \cdot y + x \land x \ge 0 ) \quad \dfrac{\hoare{x = 0 \cdot y + x \land x \ge 0}{b := x}{A_1}}{\hoare{A_1[x/b]}{b := x}{A_1}}}{\hoare{x \ge 0}{b := x}{x = 0 \cdot y + b \land b \ge 0}}$$
        \centeredeq{0.9}{$(**) \ \dfrac{A \land b \ge y \supset (x = (a + 1) \cdot y + (b - y) \land b-y \ge 0) \quad \dfrac{\hoare{x = (a + 1) \cdot y + (b - y) \land b - y \ge 0}{b:= b - y}{A_2}}{\hoare{A_2[(b - y)/b]}{b: = b - y}{A_2}}}{\hoare{A \land b \ge y}{b := b - y}{x = (a + 1) \cdot y + b \land b \ge 0}}$}
        \centeredeq{0.9}{$\dfrac{\dfrac{(*) \quad \dfrac{\hoare{x = 0 \cdot y + b \land b \ge 0}{a := 0}{A}}{\hoare{A[0/a]}{a := 0}{A}}}{\hoare{x \ge 0}{b := x; \ a := 0}{A}} \quad \dfrac{\dfrac{(**) \quad \dfrac{\hoare{x = (a + 1) \cdot y + b \land b \ge 0}{a:=a+1}{A}}{\hoare{A[(a+1)/a]}{a:= a +1}{A}}}{\hoare{A \land b \ge y}{b := b - y; \ a := a + 1}{A}}}{\hoare{A}{\while{b \ge y}{(b := b - y; \ a := a + 1)}}{A \land b < y}}}{\hoare{x \ge 0}{b :=x; \ a := 0; \ \while{b \ge y}{(b := b - y ; \ a := a + 1)}}{x = a \cdot y + b \land 0 \le b < y}}$}

        dove $$\centeredsoe{A := x = a \cdot y + b \land b \ge 0 \\ A_1 := A[0/a] \longrightarrow x = 0 \cdot y + b \land b \ge 0 \\ A_2 := A[(a + 1)/a] \longrightarrow x = (a + 1) \cdot y + b \land b \ge 0}$$

        Si noti che la postcondizione scelta per dimostrare la correttezza del programma, ovvero $$x = a \cdot y + b \land 0 \le b < y$$ è valida poiché ad ogni ciclo, fintanto che $b \ge y$, il programma sottrae $y$ da $b$, ed aggiunge 1 ad $a$, dunque $a$ risulta essere il numero di volte che è stato possibile sottrarre $y$ da $b$ --- che rappresenta la parte intera del quoziente $\dfrac{x}{y}$ --- mentre $b$ è il resto della divisione --- poiché è la parte che non è stato possibile sottrarre da $b$.

        Inoltre, la tripla di Hoare è sempre soddisfatta, poiché nel caso limite in cui $y \ge 0$, il programma non termina e dunque la tripla è soddisfatta a vuoto.
    \end{example}

    \section{Correttezza nel paradigma funzionale}

    \subsection{Formule funzionali}

    \begin{frameddefn}[label={fun formula}]{Formula funzionale}
        Si definisce \tbf{formula funzionale} un'espressione appartenente alla seguente grammatica: $$\varphi \ ::= \ \forall x.\varphi \smid M = N$$ dunque l'unico predicato presente è l'uguaglianza, denotato con il simbolo $=$.
    \end{frameddefn}

    \begin{framedprop}[label={= rules}, breakable]{Inferenza delle formule funzionali}
        Si considerino le formule funzionali descritte all'interno della \cref{fun formula}; allora, si definiscono le seguenti regole di inferenza, espresse attraverso la sintassi della grammatica $Fun_\rho$ definita nella \cref{fun rho}:

        \begin{itemize}
            \item \tbf{regola $\alpha$}: $$\fn{x}{M} = \fn{y}{M[y/x]}$$ si noti che questa regola coincide con l'alfa equivalenza descritta nella \cref{alpha equiv} del lambda calcolo;
            \item \tbf{regola $\beta$}: $$(\fn{x}{M})\ N = M[N/x]$$ si noti che questa regola coincide con la beta conversione, descritta nella \cref{beta conv}, del lambda calcolo;
            \item \tbf{regola del caso base}: $$\recfun{M}{N} \ 0 = M$$ (in accordo con l'\cref{rec obs});
            \item \tbf{regola del passo ricorsivo}: $$\recfun{M}{N} \ (\succfn \ L) = N \ (\recfun{M}{N} \ L) \ L$$ (in accordo con l'\cref{rec obs});
            \item \tbf{regola dell'induzione}: $$\dfrac{P(0) \quad P(n) \implies P(\succfn \ n)}{\forall n \quad P(n)}$$
            \item \tbf{regola dell'uguaglianza}: $$\dfrac{M = N \quad M = L}{N = L}$$
            \item \tbf{regola del contesto}: $$\dfrac{M = N \quad M' = N'}{MN = M'N'}$$
            \item \tbf{regola $\xi$}: $$\dfrac{M= N}{\fn{x}{M} = \fn{x}{N}}$$
        \end{itemize}
    \end{framedprop}

    \begin{framedprop}[label={reflex}]{Riflessività del predicato di uguaglianza}
        Si consideri il predicato di uguaglianza $=$; allora, si verifica che $$M = M$$ per ogni espressione $M$.
    \end{framedprop}

    \begin{proof}
        Attraverso le regole definite nella \cref{= rules}, data un espressione $M$ si ha che $$\dfrac{\dfrac{M}{(\recfun{M}{N}) \ 0 = M \quad (\recfun{M}{N}) \ 0 = M }}{M = M}$$
    \end{proof}

    \begin{framedprop}[label={= symm}]{Simmetria del predicato di uguaglianza}
        Si consideri il predicato di uguaglianza $=$; allora, si verifica che $$\dfrac{M = N}{N = M}$$ per ogni coppia di espressioni $M$ ed $N$.
    \end{framedprop}

    \begin{proof}
        Attraverso le regole definite nella \cref{= rules}, ed utilizzando la riflessività (dimostrata nella \cref{reflex}), data una coppia di espressioni $M$ ed $N$ si ha che $$\dfrac{\dfrac{\dfrac{M = N}{M = N \quad M}}{M = N \quad M = M}}{N = M}$$
    \end{proof}

    \begin{framedprop}[label={= trans}]{Transitività del predicato di uguaglianza}
        Si consideri il predicato di uguaglianza $=$; allora, si verifica che $$\dfrac{M = N \quad N = L}{M = L}$$ per ogni terna di espressioni $M$, $N$ ed $L$.
    \end{framedprop}

    \begin{proof}
        Attraverso le regole definite nella \cref{= rules}, e utilizzando la simmetria (dimostrata nella \cref{= symm}), data una terna di espressioni $M$, $N$ ed $L$ si ha che $$\dfrac{\dfrac{M = N \quad N = L}{N = M \quad N = L}}{M = L}$$
    \end{proof}

    \begin{example}[Correttezza di espressioni]
        Si consideri l'operazione $\mathrm{plus}$, definita all'interno del \cref{plus def}; si vuole dimostrare che $$\mathrm{plus} \ M \ N = \mathrm{plus} \ N \ M$$ per ogni coppia di espressioni $M$ ed $N$, dunque si vuole mostrare che l'operazione $\mathrm{plus}$ è commutativa.

        TODO
    \end{example}

    \chapter{Elementi di Teoria dei Tipi}

    \section{Lambda calcolo tipato semplice}

    \subsection{Definizioni}

    \begin{frameddefn}{Lambda calcolo tipato semplice}
        La grammatica del \tbf{lambda calcolo tipato semplice} (noto in letteratura come \tit{System F1}) è costituita dalle seguenti grammatiche:

        \begin{center}
            \begin{tabular}{rcl}
                $A, B$ & $::=$ & $K \smid A \to B$ \\
                $M, N$ & $::=$ & $k \smid x \smid \lambda x:A.M \smid MN$ \\
            \end{tabular}
        \end{center}

        Dunque, essa è composta da da:

        \begin{itemize}
            \item una grammatica per i \tit{tipi}, che verrà indicata con $Types$; si noti che il simbolismo $A \to B$ indica il tipo di una funzione che prende in ingresso un termine di tipo $A$, e ne restituisce uno di tipo $B$;
            \item una grammatica per i \tit{termini}, che verrà indicata con $Terms$; si noti che il simbolismo $\lambda x: A.M$ indica una funzione che prende in ingresso un termine di tipo $A$, ed ha l'espressione $M$ come suo corpo.
        \end{itemize}

        Il \tit{System F1} è \tbf{monomorfo}, poiché un termine ha \tit{uno ed un solo tipo}.
    \end{frameddefn}

    \begin{frameddefn}{Contesto dei tipi di una grammatica}
        Data una grammatica tipata $G$, le cui grammatiche delle espressioni e dei tipi sono indicate rispettivamente con $Terms$ e $Types$, un \tbf{contesto dei tipi} della grammatica  è una funzione della forma $$\Gamma : \mathrm{Var} \stackrel{fin}{\to} Types$$ che associa dunque una variabile ad un possibile tipo. L'insieme di tutti i contesti della grammatica è denotato con $$\mathrm{Ctx} := \{f \mid \mathrm{Var} \stackrel{fin}{\to} Types\}$$ In simboli, i contesti verranno scritti come liste di coppie $M:A$ con $M \in Terms, A \in Types$, che descriveranno la mappa definita dal contesto stesso. Si noti che, per un certo contesto $\Gamma \in \mathrm{Ctx}$, $\Gamma(x)$ è indefinito per ogni $A \in Types - \dom(\Gamma)$.
    \end{frameddefn}

    \begin{frameddefn}{Concatenazione di contesti}
        Siano $\Gamma_1$ e $\Gamma_2$ due contesti di una grammatica tipata; allora, si definisce \tbf{concatenazione} di $\Gamma_1$ e $\Gamma_2$ la seguente funzione $$\funcmap{\Gamma_1, \Gamma_2}{\mathrm{Ctx} \times \mathrm{Ctx}}{\mathrm{Ctx}}{x}{\soe{ll}{\Gamma_2(x) & x \in \dom(\Gamma_2) \lor x \in \dom(\Gamma_1) \cap \dom(\Gamma_2) \\ \Gamma_1(x) & x \in \dom(\Gamma_1)}}$$ dunque, nella concatenazione $\Gamma_2$ sovrascrive le tuple che sono presenti anche in $\Gamma_1$.
    \end{frameddefn}

    \begin{example}[Concatenazione di contesti]
        Si considerino i due contesti seguenti, definiti all'interno del lambda calcolo tipato semplice $$\centeredsoe{\Gamma_1 := M: A, N:B \\ \Gamma_2 := M:C}$$ allora, si ha che $$\Gamma_1,\Gamma_2 = M:C,N:B$$
    \end{example}

    \begin{frameddefn}[breakable]{Giudizi di tipi}
        Data una grammatica tipata $G$, si definisce \tbf{semantica di tipi} della grammatica una relazione, indicata col simbolo $:$, definita come segue: $$: \ \subseteq \mathrm{Ctx} \times Terms \times Types$$ dove $Terms$ e $Types$ indicano rispettivamente le grammatiche delle espressioni e dei tipi di $G$.
        Un elemento $(\Gamma, M, A) \in \ :$ è detto \tbf{giudizio di tipo}, e viene scritto attraverso il seguente simbolismo: $$\typejud{\Gamma}{M}{A}$$ per qualche espressione $M$ e tipo $A$, e si legge \curlyquotes{$M$ è un termine legale di tipo $A$ nel contesto dei tipi $\Gamma$}.
    \end{frameddefn}

    \begin{framedprop}[label={sys f1 rules}]{Regole di inferenza di \tit{System F1}}
        Dato un contesto di tipi $\Gamma \in \mathrm{Ctx}$, le regole di inferenza del lambda calcolo tipato sono le seguenti:

        \begin{itemize}
            \item \tbf{costanti}: $$[const] \ \typejud{\Gamma}{k}{K}$$ dove $K := \{\ttt{int}, \ttt{string}, \ttt{bool}\}$
            \item \tbf{variabili}: $$\exists A \in Types \mid \Gamma(x) = A \implies [vars] \ \typejud{\Gamma}{x}{A}$$
            \item \tbf{applicazioni}: $$[appl] \ \dfrac{\typejud{\Gamma}{M}{A \to B} \quad \typejud{\Gamma}{N}{A}}{\typejud{\Gamma}{MN}{B}}$$
            \item \tbf{funzioni}: $$[fn] \ \dfrac{\typejud{\Gamma,x:A}{M}{B}}{\typejud{\Gamma}{\lambda x: A.M}{A \to B}}$$
        \end{itemize}
    \end{framedprop}

    \begin{example}[Derivazione di tipi]
        Si consideri la seguente espressione, descritta attraverso le espressioni del lambda calcolo tipato: $$(\lambda x:\ttt{int}\to \ttt{bool}.x((\lambda y:\ttt{string}.7)\ttt{"ciao"}))(\lambda z: \ttt{int}.true)$$ dunque, per derivare il suo tipo, è necessario sviluppare il seguente albero di derivazione: 
        \centeredeq{0.9}{$
            \dfrac{
                \dfrac{
                    \dfrac{
                        \typejud{\Gamma}{x : \ttt {int}}{\ttt{int} \to \ttt{bool}}
                        \quad
                        \dfrac{
                            \dfrac{
                                \typejud{\Gamma,y:\ttt{string}}{7}{\ttt{int}}
                            }{
                                \typejud{\Gamma}{\lambda y: \ttt{string}.7}{ \ttt{string} \to \ttt{int}}
                            }
                            \quad
                            \typejud{\Gamma}{\ttt{"ciao"}}{\ttt{string}}
                        }{
                            \typejud{\Gamma}{(\lambda y:\ttt{string}.7)\ttt{"ciao"}}{\ttt{int}}
                        }
                    }{
                        \typejud{x:\ttt{int} \to \ttt{bool}}{x((\lambda y:\ttt{string}.7)\ttt{"ciao"})}{\ttt{bool}}
                    }
                }{
                    \typejud{\varnothing}{\lambda x:\ttt{int}\to \ttt{bool}.x((\lambda y:\ttt{string}.7)\ttt{"ciao"}}{(\ttt{int}\to\ttt{bool})\to\ttt{bool}}
                }
                \quad
                \dfrac{
                    \typejud{z:\ttt{int}}{true}{\ttt{bool}}
                }{
                    \typejud{\varnothing}{\lambda z:\ttt{int}.true}{\ttt{int} \to \ttt{bool}}
                }
            }{
                \typejud{\varnothing}{(\lambda x:\ttt{int}\to \ttt{bool}.x((\lambda y:\ttt{string}.7)\ttt{"ciao"}))(\lambda z: \ttt{int}.true)}{\ttt{bool}}
            }
        $}

        dove $$\Gamma := x: \ttt{int} \to \ttt{bool}$$
    \end{example}

    \begin{framedlem}[label={lambda type non type}]{Espressioni non tipabili}
        Non tutte le espressioni del lambda calcolo tipato semplice sono tipabili.
    \end{framedlem}

    \begin{proof}
        Si consideri la seguente espressione: $$\lambda x. xx$$ espressa in termini del lambda calcolo non tipato; provando a tipare tale espressione, si ottiene il seguente albero di derivazione: $$\dfrac{\dfrac{\typejud{x:A}{x}{A \to B} \quad \typejud{x:A}{x}{A}}{\typejud{x:A}{xx}{B}}}{\typejud{\varnothing}{\lambda x: A .xx}{A \to B}}$$ per certi tipi $A$ e $B$, ma poiché in tale albero compare il giudizio $$\typejud{x:A}{x}{A \to B}$$ segue necessariamente che $A \to B$ deve coincidere con $A$, ma questo non è possibile poiché $A \to B$ avrà sempre una $\to$ in più di $A$, indipendentemente dal tipo di quest'ultimo; dunque, segue la tesi.
    \end{proof}

    \begin{framedobs}{Tipi infiniti}
        Si consideri la dimostrazione del \cref{lambda type non type}; essa verte sul numero di $\to$ presenti all'interno del tipo considerato, dunque un tipo \tit{infinito} come ad esempio $$C \to C \to C \to C \to C \to \cdots$$ potrebbe rendere falso l'argomento utilizzato all'interno della dimostrazione, poiché entrambe i tipi considerati avrebbero un numero di $\to$ infinito. In realtà, questo non costituisce un controesempio poiché i tipi infiniti non sono presenti nell'algebra induttiva dei tipi del lambda calcolo tipato semplice, definita come $$(Types, K, \to)$$ Infatti, siano per assurdo inclusi i tipi infiniti all'interno di tale algebra induttiva; allora esisterebbe un sottoinsieme dell'algebra considerata, ovvero $Types$ stesso, tale da costituire un'algebra induttiva, e dunque verrebbe violato l'assioma \tit{iii} della \cref{inductive algebra}.
    \end{framedobs}

    \begin{framedprop}{Ricorsione in \tit{System F1}}
        Ogni termine di \tit{System F1} termina.
    \end{framedprop}

    \begin{proof}
        Omessa.
    \end{proof}

    \section{Lambda calcolo polimorfo}
    
    \subsection{Polimorfismo}

    \begin{frameddefn}{Polimorfismo}
        Con \tbf{polimorfismo} si definisce la possibilità, per un'espressione, di assumere molteplici tipi, in base al contesto considerato. Le grammatiche polimorfe sono caratterizzate da \tbf{variabili di tipo}, che permettono di descrivere in maniera \tit{generica} le loro espressioni.
    \end{frameddefn}

    \begin{frameddefn}{Clausola dei tipi polimorfi}
        La clausola dei tipi polimorfi verrà utilizzata attraverso la sintassi $$\forall \ttt{type}_1.\ttt{type}_2$$ la quale asserisce che, per ogni tipo che la varibile di tipo $\ttt{type}_1$ può assumere, il tipo polimorfo definito è $\ttt{type}_2$. Si noti che è possibile contrarre l'espressione $$\forall \ttt{type}_1.(\forall \ttt{type}_2 . \ldots .(\forall \ttt{type}_{n - 1}. \ttt{type}_n))$$ con l'espressione $$\forall \ttt{type}_1, \ttt{type}_2, \ldots, \ttt{type}_{n - 1}. \ttt{type}_n$$
    \end{frameddefn}

    \begin{example}[Tipi polimorfi]
        Si consideri ad esempio il tipo $$\forall X.X \to X$$ essa, attraverso la variabile di tipo $X$, definisce il tipo polimorfo $X \to X$ (che rappresenta una funzione che prende in ingresso un'espressione di tipo $X$ e restituisce a sua volta un'espressione di tipo $X$).
    \end{example}

    \begin{frameddefn}{Clausola di astrazione dei tipi}
        La clausola di astrazione dei tipi verrà utilizzata attraverso la sintassi $$\Lambda \ttt{type}.\ttt{expression}$$ la quale dichiara la variabile di tipo \ttt{type} all'interno dell'espressione \ttt{expression}.
    \end{frameddefn}

    \begin{frameddefn}{Clausola di istanziazione dei tipi}
       La clausola di istanziazione dei tipi verrà utilizzata attraverso la sintassi $$\ttt{expression} \ \ttt{type}$$ la quale istanzia il tipo \ttt{type} all'interno dell'espressione \ttt{expression}.
    \end{frameddefn}

    \begin{framedobs}{Istanziazione dei tipi}
        Si noti che, per utilizzare un'espressione polimorfa, è necessario prima istanziarne (o \tit{specializzarne}) il tipo.
    \end{framedobs}

    \subsection{Lambda calcolo polimorfo}

    \begin{frameddefn}{Lambda calcolo polimorfo}
        La grmamatica del \tbf{lambda calcolo polimorfo} (noto in letteratura come \tit{System F}) è costituita dalle seguenti grammatiche

        \begin{center}
            \begin{tabular}{rcl}
                $A, B$ & $::=$ & $K \smid X \smid A \to B \smid \forall X.A$ \\
                $M, N$ & $::=$ & $k \smid x \smid \lambda x:A.M \smid MN \smid \Lambda X.M \smid M A$ \\
            \end{tabular}
        \end{center}

        Dunque, essa è composta da
        \begin{itemize}
            \item una grammatica per i \tit{tipi}, che verrà indicata con $Types$; si noti che il simbolismo $X$ indica che la grammatica include le variabili di tipo, il cui insieme verrà indicato con $\mathrm{TypeVar}$;
            \item una grammatica per i \tit{termini}, che verrà indicata con $Terms$.
        \end{itemize}
    \end{frameddefn}

    \begin{framedprop}[label={regole system F}]{Regole di inferenza di \tit{System F}}
        Dato un contesto di tipi $\Gamma \in \mathrm{Ctx}$, le regole di inferenza del lambda calcolo polimorfo estendono quelle definite all'interno della \cref{sys f1 rules}, attraverso le seguenti:

        \begin{itemize}
            \item \tbf{generalizzazioni}: $$\exists X \in \mathrm{TypeVar} \mid X \notin \mathrm{free}(\Gamma) \implies [gen] \ \dfrac{\typejud{\Gamma}{M}{A}}{\typejud{\Gamma}{\Lambda X.M}{\forall X.A}}$$
            \item \tbf{specializzazioni}: $$\quad [spec] \ \dfrac{\typejud{\Gamma}{M}{\forall X.A}}{\typejud{\Gamma}{MB}{A[B/X]}}$$
        \end{itemize}
    \end{framedprop}

    \begin{example}[Tipo dell'identità polimorfa]
        Si consideri la seguente espressione, che rappresenta l'identità polimorfa: $$\Lambda X.\lambda x:X.x$$ è possibile dedurne il tipo attraverso il seguente albero di derivazione $$\dfrac{\dfrac{\typejud{x :X}{x}{X}}{\typejud{\varnothing}{\lambda x:X.x}{X \to X}}}{\typejud{\varnothing}{\Lambda X.\lambda x:X .x}{\forall X.X \to X}}$$ ed istanziando ad esempio il tipo \ttt{int} su di essa, si ottiene il seguente albero: $$\dfrac{\dfrac{\dfrac{\typejud{x :X}{x}{X}}{\typejud{\varnothing}{\lambda x:X.x}{X \to X}}}{\typejud{\varnothing}{\Lambda X.\lambda x:X .x}{\forall X.X \to X}}}{\typejud{\varnothing}{(\Lambda X.\lambda x :X.x) \ \ttt{int}}{\ttt{int} \to \ttt{int}}}$$
    \end{example}

    \begin{framedobs}{Cattura delle variabili di tipo}
        Si consideri il seguente albero di derivazione: $$\dfrac{\dfrac{\dfrac{\dfrac{\typejud{x:X}{x}{X}}{\typejud{x:X}{\Lambda X.x}{\forall X.X}}}{\typejud{x:X}{(\Lambda X.x) \ \ttt{int}}{\ttt{int}}}}{\typejud{\varnothing}{\lambda x:X.(\Lambda X.x) \ \ttt{int}}{\ttt{int}}}}{\typejud{\varnothing}{\Lambda X.\lambda x:X.(\Lambda X.x) \ \ttt{int}}{\forall X.X \to \ttt{int}}}$$ e posto $$M := \Lambda X.\lambda x:X.(\Lambda X.x) \ \ttt{int}$$ si può ad esempio derivare che $$\dfrac{\dfrac{\typejud{\varnothing}{M}{\forall X.X \to \ttt{int}}}{\typejud{\varnothing}{M \ (\ttt{int} \to \ttt{int})}{(\ttt{int} \to \ttt{int}) \to \ttt{int}}} \quad \dfrac{\typejud{\varnothing}{M}{\forall X.X \to \ttt{int}}}{\typejud{\varnothing}{M \ \ttt{int}}{\ttt{int} \to \ttt{int}}}}{\typejud{\varnothing}{M \ (\ttt{int} \to \ttt{int}) \ (M \ \ttt{int})}{\ttt{int}}}$$ il che è necessariamente falso, poiché $M$ rappresenta una lambda astrazione non applicata, e dunque non può in alcun modo avere come tipo \ttt{int}. Questo assurdo è stato raggiunto poiché è stata violata la condizione della regola della generalizzazione, descritta all'interno della \cref{regole system F}: nel primo albero di derivazione, nel passaggio $$\dfrac{\typejud{x:X}{x}{X}}{\typejud{x:X}{\Lambda X.x}{\forall X.X}}$$ la variabile di tipo $X$ era in $\mathrm{free}(\Gamma)$, ed il tipo $\forall X.X$ l'ha catturata, ma la $X$ presente in $x:X$, e quella presente in $\forall X.X$ sono $X$ \tit{diverse}: infatti, è solo un caso che entrambe le variabili di tipo si chiamino $X$ TODO DA CAPIRE CHE STO A SCRIVE PERCHÉ NON MI È CHIARO NIENTE
    \end{framedobs}

    \begin{framedobs}[label={exp poly typable}]{Espressioni polimorficamente tipabili}
        Si consideri l'espressione $$\lambda x.xx$$ discussa all'interno della dimostrazione del \cref{lambda type non type}; diversamente dal \tit{System F1}, all'interno del \tit{System F}, poiché polimorfo, è possibile tipare tale espressione, ad esempio come segue: $$\dfrac{\dfrac{\dfrac{\typejud{\Gamma}{x}{\forall X.X \to \ttt{int}}}{\typejud{\Gamma}{x \ (\ttt{int} \to \ttt{int})}{(\ttt{int} \to \ttt{int}) \to \ttt{int}}} \quad \dfrac{\typejud{\Gamma}{x}{\forall X. X \to \ttt{int}}}{\typejud{\Gamma}{x \ \ttt{int}}{\ttt{int} \to \ttt{int}}}}{\typejud{x:\forall X.X \to \ttt{int}}{x \ (\ttt{int} \to \ttt{int}) \ (x \ \ttt{int})}{\ttt{int}}}}{\typejud{\varnothing}{\lambda x:\forall X.X \to \ttt{int}.x \ (\ttt{int} \to \ttt{int}) \ (x \ \ttt{int})}{(\forall X .X \to \ttt{int}) \to \ttt{int}}}$$ dove $$\Gamma := x : \forall X.X \to \ttt{int}$$ Ciononostante, l'espressione $\omega$ della grammatica $Fun$, che è stata presentata all'interno dell'\cref{omega fun}, ovvero $$(\lambda x. xx) (\lambda x. xx)$$ resta non tipabile nel \tit{System F} (di cui se ne omette la dimostrazione).
    \end{framedobs}

    \begin{framedthm}{Sistema di tipi del \tit{System F}}
        Il sistema di tipi del \tit{System F} è indecidibile.
    \end{framedthm}

    \begin{proof}
        Omessa.
    \end{proof}

    \begin{framedprop}{Ricorsione in \tit{System F}}
        Ogni termine di \tit{System F} termina.
    \end{framedprop}

    \begin{proof}
        Omessa.
    \end{proof}

    \section{$Fun_\tau$: un linguaggio tipato polimorfo}

    \subsection{Definizioni}

    \begin{frameddefn}{Istanza generica}
        Siano $\sigma$ e $\sigma'$ i seguenti tipi: $$\centeredsoe{\sigma := \forall X_1, \ldots, X_n. \tau \\ \sigma' := \forall Y_1, \ldots, Y_m. \tau'}$$ Allora, $\sigma'$ si dice essere un'\tbf{istanza generica} di $\sigma$ --- e viene denotato con il simbolismo $$\sigma > \sigma '$$ se e solo se:

        \begin{itemize}
            \item $\exists \tau_1, \ldots, \tau_n \mid \tau' = [\tau_1, \ldots , \tau_n/X_1, \ldots, X_n]$ --- dove quest'ultima indica una sostituzione simultanea (si noti che $\nexists j \in [1, n] \mid X_j \in \mathrm{free}(\sigma)$)
            \item $\nexists j \in [1, m] \mid Y_j \in \mathrm{free}(\sigma)$
        \end{itemize}
    \end{frameddefn}

    \begin{example}[Istanze generiche]
        Dato il tipo $$\sigma := \forall X_1, X_2.X_1 \to X_2$$ si verifica che il tipo $\sigma'$, definito come $$\sigma' := \forall Z. (\ttt{int} \to Z) \to \ttt{bool}$$ è un'istanza generica di $\sigma$, poiché $$\soe{l}{\tau_1 := \ttt{int} \to Z \\ \tau_2 := \ttt{bool}} \implies \exists \tau_1, \tau_2 \mid \tau' := (\ttt{int} \to Z) \to \ttt{bool} = (X_1 \to X_2)[\tau_1, \tau_2/X_1, X_2]$$ ed inoltre $Z \notin \mathrm{free}(\sigma)$.
    \end{example}

    \begin{example}[Istanze generiche]
        Dato il tipo $$\sigma := \forall X,Y.X \to Y$$ si verifica che il tipo $\sigma'$, definito come $$\sigma' := X \to Y$$ è un'istanza generica di $\sigma$, poichè $\sigma'$ è semplicemente diventato non ulteriormente specializzabile.
    \end{example}

    \begin{example}[Istanze generiche]
        Dato il tipo $$\sigma := X$$ si verifica che il tipo $\sigma'$, definito come $$\sigma' := \forall Y.X$$ è un'istanza generica di $\sigma$, poichè $X$ è stato sostituito con sé stesso, e $Y \notin \mathrm{free}(\sigma)$.
    \end{example}

    \begin{example}[Istanze generiche]
        Dato il tipo $$\sigma := \forall X.X$$ si verifica che il tipo $\sigma'$, definito come $$\sigma' := \forall Y.X$$ è un'istanza generica di $\sigma$, poichè $X$ è stato sostituito con sé stesso, e $Y \notin \mathrm{free}(\sigma)$.
    \end{example}

    \begin{nonexample}[Istanze generiche]
        Dato il tipo $$\sigma := \forall X.Y \to X$$ si verifica che il tipo $\sigma'$, definito come $$\sigma' := \forall Y.(\ttt{int} \to Y) \to X$$ \tit{non} è un'istanza generica di $\sigma$, poiché $Y \in \mathrm{free}(\sigma)$.
    \end{nonexample}

    \begin{nonexample}[Istanze generiche]
        Dato il tipo $$\sigma := X \to Y$$ si verifica che il tipo $\sigma'$, definito come $$\sigma' := \ttt{int} \to Y$$ \tit{non} è un'istanza generica di $\sigma$, poiché $\sigma$ non è specializzabile.
    \end{nonexample}

    \begin{nonexample}[Istanze generiche]
        Dato il tipo $$\sigma := X$$ si verifica che il tipo $\sigma'$, definito come $$\sigma' := \forall X.X$$ \tit{non} è un'istanza generica di $\sigma$, poiché $X \in \mathrm{free}(\sigma)$.
    \end{nonexample}

    \begin{framedobs}{Non-antisimmetria delle istanze}
        Si considerino i due tipi seguenti: $$\centeredsoe{\sigma := \forall Z.X \\ \sigma' := \forall W.X}$$ e si noti che $$\soe{l}{\tau_1 := X \implies \exists \tau_1 \mid \tau' := X = (X)[\tau_1/Z] \\ W \notin \mathrm{free}(\sigma)} \iff \sigma > \sigma'$$ ed inoltre $$\soe{l}{\tau_1 := X \implies \exists \tau_1 \mid \tau' := X = (X)[\tau_1/W] \\ Z \notin \mathrm{free}(\sigma')} \iff \sigma' > \sigma$$ Allora esistono tipi tali per cui $$\soe{l}{\sigma > \sigma ' \\ \sigma' > \sigma}$$ nonostante $\sigma \neq \sigma'$. Allora la relazione $>$ non è antisimmetrica.
    \end{framedobs}

    \begin{frameddefn}{Grammatica $Fun_\tau$}
        Sia $Fun_\tau$ la grammatica tipata polimorfa seguente:

        \begin{center}
            \begin{tabular}{rcl}
                $\tau$ & $::=$ & $K \smid X \smid \tau_1 \to \tau_2$ \\
                $\sigma$ & $::=$ & $\tau \smid \forall X.\sigma$ \\
                $M, N$ & $::=$ & $k \smid x \smid \fn{x}{M} \smid MN \smid \letin{x}{M}{N}$ \\
            \end{tabular}
        \end{center}

        Dunque, essa è composta da:

        \begin{itemize}
            \item due grammatiche per i \tit{tipi}, che verranno indicate genericamente con $Types$; gli elementi della prima grammatica prendono il nome di \tit{tipi primitivi} (la cui grammatica verrà indicata con $PrimTypes$), mentre quelli della seconda prendono il nome di \tit{schemi di tipo};
            \item una grammatica per i \tit{termini}, che verrà indicata con $Terms$.
        \end{itemize}

        Si noti che questa grammatica è la stessa che viene utilizzata all'interno del linguaggio di progarmmazione \href{https://it.wikipedia.org/wiki/Standard_ML}{Standard ML}.
    \end{frameddefn}

    \begin{framedobs}{Tipi di $Fun_\tau$}
        La definizione dei tipi di $Fun_\tau$ è scomposta in due grammatiche differenti, al fine di vietare di costruire tipi come il seguente: $$(\forall X.X )\to \ttt{int}$$ infatti, non è possibile avere questo tipo in $Fun_\tau$, poiché una volta costruito il tipo $\forall X.X$, il quale è uno schema di tipo, non è legale utilizzare la regola $\tau_1 \to \tau_2$, poiché $\tau_1$ e $\tau_2$ devono essere tipi primitivi.

        Di conseguenza, i tipi di $Fun_\tau$ non permettono di definire funzioni che in input si aspettano tipi polimorfi, ed infatti l'espressione $$\lambda x.xx$$ discussa nell'\cref{exp poly typable} non è tipabile in $Fun_\tau$.
    \end{framedobs}

    \begin{framedprop}[breakable]{Regole di inferenza di $Fun_\tau$}
        Dato un contesto di tipi $\Gamma \in \mathrm{Ctx}$, le regole di inferenza di $Fun_\tau$ estendono le regole $$[const], \ [vars]$$ definite all'interno della \cref{sys f1 rules} attraverso le seguenti:

        \begin{itemize}
            \item \tbf{generalizzazioni}: $$\exists X \in \mathrm{TypeVar} \mid X \notin \mathrm{free}(\Gamma) \implies [gen] \ \dfrac{\typejud{\Gamma}{M}{\sigma}}{\typejud{\Gamma}{M}{\forall X.\sigma}}$$
            \item \tbf{specializzazioni}: $$\sigma > \sigma ' \implies [spec] \ \dfrac{\typejud{\Gamma}{M}{\sigma}}{\typejud{\Gamma}{M}{\sigma'}}$$
            \item \tbf{applicazioni}: $$[appl] \ \dfrac{\typejud{\Gamma}{M}{\tau' \to \tau} \quad \typejud{\Gamma}{N}{\tau'}}{\typejud{\Gamma}{MN}{\tau}}$$
            \item \tbf{funzioni}: $$[fn] \ \dfrac{\typejud{\Gamma,x:\tau'}{M}{\tau}}{\typejud{\Gamma}{\fn{x}{M}}{\tau' \to \tau}}$$
            \item \tbf{assegnazioni}: $$[let] \ \dfrac{\typejud{\Gamma}{M}{\sigma} \quad \typejud{\Gamma, x:\sigma}{N}{\sigma'}}{\typejud{\Gamma}{\letin{x}{M}{N}}{\sigma'}}$$
        \end{itemize}
    \end{framedprop}

    \begin{example}[Derivazione di tipi]
        Si consideri l'espressione $$\letin{x}{(\fn{y}{y})}{x \ (\fn{z}{z}) \ (x \ 5)}$$ è possibile derivarne il tipo attraverso il seguente albero di derivazione: $$(*) \ \dfrac{\dfrac{\typejud{\Gamma}{x}{\forall Y . Y \to Y}}{\typejud{\Gamma}{x}{(\ttt{int} \to \ttt{int}) \to (\ttt{int} \to \ttt{int})}} \quad \dfrac{\dfrac{\dfrac{\typejud{\Gamma, z:Z}{z}{Z}}{\typejud{\Gamma}{\fn{z}{z}}{Z \to Z}}}{\typejud{\Gamma}{\fn{z}{z}}{\forall Z . Z \to Z}}}{\typejud{\Gamma}{\fn{z}{z}}{\ttt{int} \to \ttt{int}}}}{\typejud{\Gamma}{x \ (\fn{z}{z})}{\ttt{int} \to \ttt{int}}}$$ $$\dfrac{\dfrac{\dfrac{\typejud{y:Y}{y}{Y}}{\typejud{\varnothing}{\fn{y}{y}}{Y \to Y}}}{\typejud{\varnothing}{\fn{y}{y}}{\forall Y.Y \to Y}} \quad \dfrac{(*) \quad \dfrac{\dfrac{\typejud{\Gamma}{x}{\forall Y.Y \to Y}}{\typejud{\Gamma}{x}{\ttt{int} \to \ttt{int}}} \quad \typejud{\Gamma}{5}{\ttt{int}}}{\typejud{\Gamma}{x \ 5}{\ttt{int}}}}{\typejud{x: \forall Y .Y \to Y}{x \ (\fn{z}{z}) \ (x \ 5)}{\ttt{int}}}}{\typejud{\varnothing}{\letin{x}{(\fn{x}{x})}{x \ (\fn{z}{z}) \ (x \ 5)}}{\ttt{int}}}$$
    \end{example}

    \subsection{Algoritmo $\mathcal{W}$}

    \begin{frameddefn}{Sostituzione}
        Si definisce \tbf{sostituzione} una morfismo parziale --- in cui gli input non presenti nel dominio vengono mandati in loro stessi --- sull'operatore $\to$, che mappa variabili di tipo a tipi primitivi; in simboli $$V: \mathrm{TypeVar} \stackrel{fin}{\to} PrimTypes$$
    \end{frameddefn}

    \begin{frameddefn}{Unificatore}
        Siano $\tau_1$ e $\tau_2$ due tipi primitivi; allora, una sostituzione $V$ è detta \tbf{unificatore di tipi primitivi} se $$V(\tau_1) = V(\tau_2)$$
    \end{frameddefn}

    \begin{example}[Unificatori]
        Siano $\tau_1$ e $\tau_2$ i seguenti tipi primitivi: $$\centeredsoe{\tau_1 := A \to B \to C \\ \tau_2 := (C \to E) \to D}$$ e sia $V$ una sostituzione definita insiemisticamente come $$V := \{(A, C \to E), (D, B \to C)\}$$ allora, poiché $$\centeredsoe{V(\tau_1) = V(A \to B \to C) = V(A) \to B \to C = \\ = (C \to E) \to B \to C = \\ =  (C \to E) \to V(D) = V(( C \to E) \to D) =  V(\tau_2)}$$ si ha che $V$ è unificatore di $\tau_1$ e $\tau_2$.
    \end{example}

    \begin{nonexample}[Unificatori]
        Siano $\tau_1$ e $\tau_2$ i seguenti tipi primitivi: $$\centeredsoe{\tau_1 := A \to A \\ \tau_2 :=\ttt{int} \to \ttt{bool}}$$ per assurdo, se esistesse un unificatore $V$ di $\tau_1$ e $\tau_2$, si otterrebbe che $\ttt{int} \equiv \ttt{bool}$ $\lightning$.
    \end{nonexample}

    \begin{nonexample}[Unificatori]
        Siano $\tau_1$ e $\tau_2$ i seguenti tipi primitivi: $$\centeredsoe{\tau_1 := A \to A \to A \\ \tau_2 := B \to B}$$ per assurdo, se esistesse un unificatore $V$ di $\tau_1$ e $\tau_2$, si otterrebbe che $A \equiv A \to A$ $\lightning$.
    \end{nonexample}

    \begin{framedthm}[label={robinson}]{Teorema di unificazione di Robinson}
        Esiste un algoritmo $\mathcal U$ \tit{fallibile} che, dati due tipi primitivi $\tau_1$ e $\tau_2$, se non fallisce, restituisce una sostizuione $V$ tale che

        \begin{itemize}
            \item $V(X) \neq X$ implica che $X$ compare in $\tau_1$ o $\tau_2$
            \item $V$ è unificatore di $\tau_1$ e $\tau_2$
        \end{itemize}

        ed inoltre l'algoritmo è tale che, se esiste un unificatore $W$ di $\tau_1$ e $\tau_2$, allora

        \begin{itemize}
            \item $\mathcal U$ non può fallire
            \item esiste una sostituzione $Z$ tale che $W = Z \circ \mathcal U(\tau_1, \tau_2)$, dunque il risultato dell'algoritmo è la sostituzione più generica possibile
        \end{itemize}
    \end{framedthm}

    \begin{proof}
        Omessa.
    \end{proof}

    \begin{example}[Genericità delle sostituzioni]
    Siano $\tau_1$ e $\tau_2$ i seguenti tipi primitivi $$\centeredsoe{\tau_1 := X \to Y \\ \tau_2 := Z \to Y}$$ e siano $V$ e $W$ due sostituzioni definite insiemisticamente come $$\centeredsoe{V := \{(X, Z)\} \\ W := \{(X, Z), (Y, A \to B)\}}$$ si noti che entrambe le sostituzioni sono unificiatori di $\tau_1$ e $\tau_2$, poiché $$V(\tau_1) = V(X \to Y) = V(X) \to V(Y) = Z \to Y =: \tau_2 = V(\tau_2)$$ \centeredeq{0.9}{$W(\tau_1) = W(X \to Y) = W(X) \to W(Y) = Z \to (A \to B) = Z \to W(Y) = W(Z \to Y) = W(\tau_2)$} ma poiché la sostituzione $$U := \{(Y, A \to B)\}$$ è tale che $$W = U \circ V$$ allora $V$ è più generica di $W$.
    \end{example}

    \begin{frameddefn}{Generalizzazione massima}
        Data una variabile $x \in \mathrm{Var}$, ed un contesto $\Gamma \in \mathrm{Ctx}$, si definisce \tbf{generalizzazione massima di $x$} il seguente schema di tipo: $$\overline \Gamma (x) := \forall X_1, \ldots, X_n . \tau$$ dove $\Gamma(x) = \tau$ e $\mathrm{TypeVar} - \mathrm{free}(\Gamma) = \{ X_1, \ldots, X_n \}$.
    \end{frameddefn}

    \begin{framedthm}[breakable]{Algoritmo $\mathcal W$}
        Esiste un algoritmo $\mathcal W$ \tit{fallibile} che, dato un contesto $\Gamma \in \mathrm{Ctx}$ ed un termine $M$, se non fallisce, restituisce una tupla $(V, \tau)$ --- dove $V$ è una sostituzione e $\tau$ è un tipo --- tale che:

        \begin{itemize}
            \item se $M \equiv x$, e $$\Gamma(x) = \forall X_1, \ldots, X_n.\tau'$$ allora $$\soe{l}{V \equiv \id \\ \exists Y_1, \ldots, Y_n \in \mathrm{free}(\Gamma(x)) \mid \tau = \tau'[Y_1, \ldots, Y_n/X_1, \ldots, X_n]}$$
            \item se $M \equiv M_1 M_2$, e $$\soe{l}{\mathcal W(\Gamma, M_1) = (V_1, \tau_1) \\ \mathcal W (V_1(\Gamma), M_2) = (V_2, \tau_2) \\ \mathcal U(V_2(\tau_1), \tau_2 \to Y) = W}$$ dove $Y$ è una nuova variabile --- allora $$\soe{l}{V = W \circ V_2 \circ V_1 \\ \tau = W(Y)}$$ 
            \item se $M \equiv \fn{x}{N}$, e $$\mathcal W((\Gamma, x:X), N) = (V_1, \tau_1)$$ dove $X$ è una nuova variabile, allora $$\soe{l}{V = V_1 \\ \tau = V_1(X) \to \tau_1}$$
            \item se $M \equiv \letin{x}{N}{L}$, e $$\mathcal W((V_1(\Gamma), x: \tau'), L) = (V_2, \tau_2)$$ dove $\overline{V_1(\Gamma)}(x) = \tau'$, allora $$\soe{l}{V = V_2 \circ V_1 \\ \tau = \tau_2}$$
        \end{itemize}
        
        Inoltre, se $\mathcal U$ fallisce allora $\mathcal W$ fallisce.
    \end{framedthm}

    \begin{proof}
        Omessa.
    \end{proof}

    \begin{frameddefn}{Schema principale}
        Dato un contesto $\Gamma \in \mathrm{Ctx}$ ed un termine $M$, uno schema di tipi $\sigma$ è detto \tbf{principale per $\Gamma$ ed $M$} se:

        \begin{itemize}
            \item $\typejud{\Gamma}{M}{\sigma}$
            \item $\forall \sigma' \quad \typejud{\Gamma}{M}{\sigma'} \implies \sigma > \sigma'$
        \end{itemize}
    \end{frameddefn}

    \begin{framedthm}{Correttezza e completezza dell'algoritmo $\mathcal W$}
        Se $\mathcal W (\Gamma, M) = (V, \tau)$, allora:
        
        \begin{itemize}
            \item $\typejud{V(\Gamma)}{M}{\tau}$
            \item $\overline{V(\Gamma)}(\tau)$ è principale per $V(\Gamma)$ ed $M$
        \end{itemize}
    \end{framedthm}

    \begin{proof}
        Omessa.
    \end{proof}

\end{document}
